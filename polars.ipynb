{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3288e40f",
   "metadata": {},
   "source": [
    "# `polars` 学习簿\n",
    "\n",
    "`polars` 是一个现代化、高性能的 `DataFrame` 数据处理库，专为处理大规模数据集而设计。它采用了全新的架构理念，使用 `Rust` 语言构建，通过 `PyO3` 提供 `Python` 接口，完美结合了系统级语言的优异性能和脚本语言的易用性。\n",
    "\n",
    "不同于传统的 `pandas` 库，`polars` 从底层设计就专注于并行计算和内存效率，采用了 `Apache Arrow` 作为内存数据格式，实现了在多核处理器上的高效并行操作。其名称 `polars` 寓意着像北极星一样为数据科学家指引方向，提供高性能的数据处理解决方案。\n",
    "\n",
    "以下是 `polars` 的核心架构与技术特点：\n",
    "\n",
    "- **高性能计算引擎**：多线程并行、向量化(*SIMD*)执行、智能查询优化及高效内存管理\n",
    "- **数据类型系统**：严格类型系统，支持空值安全处理、时间序列优化及嵌套数据类型\n",
    "- **执行模式**：支持即时执行、惰性执行及自动选择的混合执行策略\n",
    "- **数据读写能力**：多格式支持（CSV/Parquet 等）、大数据分块处理、云存储集成及数据库连接\n",
    "- **数据处理操作**：提供表达式 API、聚合操作、多种连接方式及专业时间序列处理功能\n",
    "- **数据可视化集成**：与主流可视化库无缝集成，支持直接绘图和 `Jupyter` 交互探索\n",
    "- **与Python生态集成**：支持与 `pandas`、`numpy` 互操作，以及机器学习框架协同工作\n",
    "\n",
    "`polars` 代表了数据处理库的新一代发展方向，将性能、内存效率和易用性结合。无论对数据科学家、分析师还是工程师，`polars` 都能提供高效、可靠的数据处理解决方案。这个工作簿的学习，有助于快速掌握 `polars` 的核心概念与功能，以更好地在实际项目中应用这些知识，提升数据处理效率和分析能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8be6cfb",
   "metadata": {},
   "source": [
    "## 准备\n",
    "你可以通过 pip来安装 `polars`：\n",
    "\n",
    "```shell\n",
    "pip install polars\n",
    "```\n",
    "\n",
    "然后就可以在程序中引入 `polars` 库了（一般用简短的别名`pl`替代）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf83e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d693c",
   "metadata": {},
   "source": [
    "下面所有的操作都假定你已经完成了上面两步。接下来，让我们从基础着手认识 `polars`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92a661",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "`Series` 是 `polars` 中的一维数据结构，类似于 `pandas` 的 `Series` 或 `numpy` 的 `ndarray`。在一个 `Series` 中，所有元素都具有相同的数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b7f207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3,)\n",
      "Series: 'ages' [i64]\n",
      "[\n",
      "\t25\n",
      "\t30\n",
      "\t35\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "s = pl.Series(\"ages\", [25, 30, 35])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71e251b",
   "metadata": {},
   "source": [
    "在创建 `Series` 时，`polars` 会根据提供的值来推断数据类型。你也可以指定具体的数据类型来覆盖这种推断机制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61c2f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64 UInt64\n"
     ]
    }
   ],
   "source": [
    "s1 = pl.Series(\"ints\", [1, 2, 3, 4, 5])\n",
    "s2 = pl.Series(\"uints\", [1, 2, 3, 4, 5], dtype=pl.UInt64)\n",
    "print(s1.dtype, s2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc1677",
   "metadata": {},
   "source": [
    "可以使用 `name` 属性获取数组名，`dtype` 属性则表示数组的数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd715552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: ages\n",
      "Length: 3\n",
      "Data type: Int64\n",
      "Values: [25, 30, 35]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name: {s.name}\")\n",
    "print(f\"Length: {len(s)}\")\n",
    "print(f\"Data type: {s.dtype}\")\n",
    "print(f\"Values: {s.to_list()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a4dd27",
   "metadata": {},
   "source": [
    "`Series` 对象可以直接和标量数据进行运算，遵循与 `numpy` 类似的广播机制，如果需要可以先学习 `numpy` 的[相关知识](numpy.ipynb)。\n",
    "\n",
    "下面是简单的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ba8728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3,)\n",
      "Series: 'ages' [i64]\n",
      "[\n",
      "\t27\n",
      "\t32\n",
      "\t37\n",
      "]\n",
      "shape: (3,)\n",
      "Series: 'ages' [i64]\n",
      "[\n",
      "\t23\n",
      "\t28\n",
      "\t33\n",
      "]\n",
      "shape: (3,)\n",
      "Series: 'ages' [i64]\n",
      "[\n",
      "\t75\n",
      "\t90\n",
      "\t105\n",
      "]\n",
      "shape: (3,)\n",
      "Series: 'ages' [f64]\n",
      "[\n",
      "\t6.25\n",
      "\t7.5\n",
      "\t8.75\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(s + 2)\n",
    "print(s - 2)\n",
    "print(s * 3)\n",
    "print(s / 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f27a0a7",
   "metadata": {},
   "source": [
    "`Series` 也支持向量间的基本运算，比如加减乘除等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95cce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pl.Series(\"temp\", [2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c147c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3,)\n",
      "Series: 'ages' [i64]\n",
      "[\n",
      "\t27\n",
      "\t33\n",
      "\t39\n",
      "]\n",
      "shape: (3,)\n",
      "Series: 'ages' [i64]\n",
      "[\n",
      "\t23\n",
      "\t27\n",
      "\t31\n",
      "]\n",
      "shape: (3,)\n",
      "Series: 'ages' [i64]\n",
      "[\n",
      "\t50\n",
      "\t90\n",
      "\t140\n",
      "]\n",
      "shape: (3,)\n",
      "Series: 'ages' [f64]\n",
      "[\n",
      "\t12.5\n",
      "\t10.0\n",
      "\t8.75\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(s + x)\n",
    "print(s - x)\n",
    "print(s * x)\n",
    "print(s / x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d864a615",
   "metadata": {},
   "source": [
    "## Series的特点\n",
    "\n",
    "polars 和 pandas 在 `Series` 设计上存在一个显著的区别——`polars` 没有`index`概念，需要用 `alias` 重命名。理解这点能帮助我们从 `pandas` 的思维模式顺利切换到 `polars` 的思维模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185b91e6",
   "metadata": {},
   "source": [
    "在 **pandas** 中，每个 `Series` 都有一个显式的、强大的 `index`。这个 `index` 本身就是一个类似数组的对象，它可以包含标签（字符串、时间戳等），并且用于数据对齐和选择（通过 `loc`）。`Series` 的名称（`name`）是附加在 `index` 之上的一个属性。\n",
    "\n",
    "在 **polars** 中，设计哲学完全不同：\n",
    "*   **只有位置，没有显式索引**：polars 的 `Series` 从根本上认为数据就是一个**连续的内存块**。每个元素通过其**整数位置（0-based）** 来访问。它没有 Pandas 中那种可以自定义标签的 `index` 对象。\n",
    "*   **名称只是一个标签**：`Series` 的 `name` 属性在 polars 中被视为一个简单的**字符串标签**，其主要目的是在将多个 `Series` 组合成 `DataFrame` 时作为**列名**。它不参与数据对齐或选择逻辑（polars 的数据对齐是基于表达式和名称的，而不是基于索引标签）。\n",
    "\n",
    "正因为名称只是一个标签，polars 提供了 `alias` 方法来**安全、清晰地修改它**。\n",
    "\n",
    "- `alias` 的作用：安全地重命名\n",
    "\n",
    "-   **`alias` 返回一个新的 Series**：与 pandas 的 `s.rename(\"new_name\")` 类似，`s.alias(\"new_name\")` 会返回一个内容完全相同但名称被更改的新 `Series` 对象。原始 `Series` 不会被修改（符合函数式编程的不可变思想）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a58933",
   "metadata": {},
   "source": [
    "#### 在实践中意味着什么？\n",
    "\n",
    "当你想基于“标签”选择数据时，在 polars 中你需要换一种思维方式：\n",
    "\n",
    "*   **pandas (基于标签)**: `df.loc[‘row_label’, ‘column_name’]`\n",
    "*   **polars (基于表达式和过滤)**: `df.filter(pl.col(‘column_name’) == ‘value’)`。Polars 通过强大的表达式在**数据内容本身**上进行过滤和选择，而不是依赖一个外部的索引结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "607829d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Series:\n",
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "Name: old_name, dtype: int64\n",
      "Index: Index(['a', 'b', 'c'], dtype='object')\n",
      "Name: old_name\n",
      "After rename: new_pandas_name\n",
      "\n",
      "Polars Series:\n",
      "shape: (3,)\n",
      "Series: 'old_name' [i64]\n",
      "[\n",
      "\t1\n",
      "\t2\n",
      "\t3\n",
      "]\n",
      "Name: old_name\n",
      "After alias: new_polars_name\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ------------- Pandas -------------\n",
    "s_pd = pd.Series([1, 2, 3], index=['a', 'b', 'c'], name='old_name')\n",
    "print(\"Pandas Series:\")\n",
    "print(s_pd)\n",
    "print(\"Index:\", s_pd.index)\n",
    "print(\"Name:\", s_pd.name)\n",
    "s_pd_renamed = s_pd.rename(\"new_pandas_name\")\n",
    "print(\"After rename:\", s_pd_renamed.name)\n",
    "\n",
    "# ------------- Polars -------------\n",
    "s_pl = pl.Series('old_name', [1, 2, 3])\n",
    "print(\"\\nPolars Series:\")\n",
    "print(s_pl)\n",
    "print(\"Name:\", s_pl.name)\n",
    "# 使用 alias 重命名\n",
    "s_pl_renamed = s_pl.alias(\"new_polars_name\")\n",
    "print(\"After alias:\", s_pl_renamed.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486ed8c7",
   "metadata": {},
   "source": [
    "下面是为 `polars` 库的 `Series` 对象整理的常用功能表格，这个表格涵盖了 `Series` 最常用的功能，可以作为一份快速指南。\n",
    "\n",
    "| 方法名称                 | 功能描述                                         | 示例代码                                     |\n",
    "|--------------------------|--------------------------------------------------|----------------------------------------------|\n",
    "| `dtype`                  | 返回 `Series` 对象中数据的类型                  | `s.dtype`                                    |\n",
    "| `shape`                  | 返回 `Series` 对象的形状（行数）                | `s.shape`                                    |\n",
    "| `name`                   | 获取或设置 `Series` 的名称                      | `s.name` 或 `s = s.rename(\"new_name\")`       |\n",
    "| `alias(name)`            | 为 `Series` 设置别名（返回新 Series）           | `s.alias(\"new_name\")`                        |\n",
    "| `head(n)`                | 返回 `Series` 对象的前 `n` 行（默认为 5）       | `s.head(3)`                                  |\n",
    "| `tail(n)`                | 返回 `Series` 对象的后 `n` 行（默认为 5）       | `s.tail(2)`                                  |\n",
    "| `describe()`             | 返回 `Series` 对象的统计描述                     | `s.describe()`                               |\n",
    "| `is_null()`              | 返回布尔 `Series`，表示每个元素是否为 `null`     | `s.is_null()`                                |\n",
    "| `is_not_null()`          | 返回布尔 `Series`，表示每个元素是否不是 `null`  | `s.is_not_null()`                            |\n",
    "| `unique()`               | 返回 `Series` 中的唯一值（去重）                 | `s.unique()`                                 |\n",
    "| `n_unique()`             | 返回 `Series` 中唯一值的数量                    | `s.n_unique()`                               |\n",
    "| `value_counts()`        | 返回 `Series` 中每个唯一值的出现次数            | `s.value_counts()`                           |\n",
    "| `sort(descending=False)` | 对 `Series` 中的元素进行排序（按值排序）         | `s.sort()` 或 `s.sort(descending=True)`      |\n",
    "| `sample(n, fraction=None)` | 从 `Series` 中随机采样 n 个元素                | `s.sample(5)`                               |\n",
    "| `shift(periods)`        | 将 `Series` 中的元素按指定步数进行位移          | `s.shift(1)`                                 |\n",
    "| `fill_null(strategy)`   | 使用指定策略填充 `Series` 中的空值              | `s.fill_null(\"forward\")`                     |\n",
    "| `fill_nan(value)`       | 填充 `Series` 中的 NaN 值                       | `s.fill_nan(0)`                              |\n",
    "| `cast(dtype)`           | 将 `Series` 转换为指定类型                       | `s.cast(pl.Float64)`                         |\n",
    "| `to_list()`             | 将 `Series` 转换为 Python 列表                   | `s.to_list()`                                |\n",
    "| `to_numpy()`            | 将 `Series` 转换为 numpy 数组                    | `s.to_numpy()`                               |\n",
    "| `cum_sum()`             | 返回 `Series` 的累计求和                        | `s.cum_sum()`                                |\n",
    "| `cum_prod()`            | 返回 `Series` 的累计乘积                        | `s.cum_prod()`                               |\n",
    "| `cum_max()`             | 返回 `Series` 的累计最大值                      | `s.cum_max()`                                |\n",
    "| `cum_min()`             | 返回 `Series` 的累计最小值                      | `s.cum_min()`                                |\n",
    "| `rank(method)`          | 返回 `Series` 中元素的排名                      | `s.rank(\"average\")`                          |\n",
    "| `diff(n)`               | 计算 `Series` 中元素的 n 阶差分                 | `s.diff(1)`                                  |\n",
    "| `pct_change(n)`         | 计算 `Series` 中元素的 n 阶百分比变化            | `s.pct_change(1)`                            |\n",
    "| `clip(min, max)`        | 将 `Series` 中的值限制在 [min, max] 范围内      | `s.clip(0, 100)`                             |\n",
    "| `is_between(lower, upper)` | 返回布尔 Series，表示元素是否在范围内         | `s.is_between(0, 100)`                       |\n",
    "| `is_in(other)`          | 返回布尔 Series，表示元素是否在另一个集合中     | `s.is_in([1, 2, 3])`                         |\n",
    "| `filter(predicate)`     | 根据谓词条件过滤 Series                         | `s.filter(pl.col(\"s\") > 5)`                  |\n",
    "| `apply(function)`       | 将函数应用于 Series 的每个元素                  | `s.apply(lambda x: x * 2)`                   |\n",
    "| `map_elements(function)` | 将函数映射到 Series 的每个元素（类型安全）      | `s.map_elements(lambda x: x * 2)`           |\n",
    "| `len()`                 | 返回 Series 的长度                              | `s.len()`                                    |\n",
    "| `min()`                 | 返回 Series 的最小值                            | `s.min()`                                    |\n",
    "| `max()`                 | 返回 Series 的最大值                            | `s.max()`                                    |\n",
    "| `mean()`                | 返回 Series 的均值                              | `s.mean()`                                   |\n",
    "| `median()`              | 返回 Series 的中位数                            | `s.median()`                                 |\n",
    "| `sum()`                 | 返回 Series 的总和                              | `s.sum()`                                    |\n",
    "| `std()`                 | 返回 Series 的标准差                            | `s.std()`                                    |\n",
    "| `var()`                 | 返回 Series 的方差                              | `s.var()`                                    |\n",
    "| `quantile(quantile)`    | 返回 Series 的分位数                            | `s.quantile(0.5)`                            |\n",
    "| `arg_min()`             | 返回最小值的索引位置                            | `s.arg_min()`                                |\n",
    "| `arg_max()`             | 返回最大值的索引位置                            | `s.arg_max()`                                |\n",
    "| `corr(other)`           | 计算与另一个 Series 的相关系数                  | `s.corr(other_series)`                       |\n",
    "| `cov(other)`            | 计算与另一个 Series 的协方差                    | `s.cov(other_series)`                        |\n",
    "| `dot(other)`            | 计算与另一个 Series 的点积                      | `s.dot(other_series)`                        |\n",
    "| `slice(offset, length)` | 从指定位置开始截取指定长度的 Series             | `s.slice(2, 5)`                             |\n",
    "| `append(other)`         | 将另一个 Series 追加到当前 Series               | `s.append(other_series)`                     |\n",
    "| `is_duplicated()`       | 返回布尔 Series，表示元素是否重复               | `s.is_duplicated()`                         |\n",
    "| `is_unique()`           | 返回布尔 Series，表示元素是否唯一               | `s.is_unique()`                              |\n",
    "| `is_finite()`           | 返回布尔 Series，表示元素是否为有限数           | `s.is_finite()`                              |\n",
    "| `is_infinite()`         | 返回布尔 Series，表示元素是否为无限数           | `s.is_infinite()`                            |\n",
    "| `is_nan()`              | 返回布尔 Series，表示元素是否为 NaN            | `s.is_nan()`                                 |\n",
    "\n",
    "请注意：\n",
    "1. `polars` 的 API 设计理念与 `Pandas` 有所不同，更加函数式和表达式导向\n",
    "2. 许多操作在 `polars` 中通常通过表达式（`pl.col(\"column_name\")`）来完成，而不是直接对 `Series` 进行操作\n",
    "3. `polars` 默认使用惰性求值，某些操作需要在惰性上下文中使用或通过 `.collect()` 触发计算\n",
    "4. 对于空值处理，`polars` 区分 `null` (缺失值) 和 `NaN` (非数字)，有不同的处理方法\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7572948",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "`DataFrame` 是 `polars` 的核心数据结构，它是一个二维表格，类似于 `pandas` 的 `DataFrame` 或关系数据库中的表。\n",
    "\n",
    "### 创建 DataFrame\n",
    "\n",
    "`polars` 支持从多种数据源创建 `DataFrame`，比如列表、字典或直接读取文件。下面是基于字典创建 `DataFrame` 的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed3eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────┬─────┬──────────┬────────┐\n",
      "│ name    ┆ age ┆ city     ┆ salary │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---    │\n",
      "│ str     ┆ i64 ┆ str      ┆ i64    │\n",
      "╞═════════╪═════╪══════════╪════════╡\n",
      "│ Alice   ┆ 25  ┆ New York ┆ 5000   │\n",
      "│ Bob     ┆ 30  ┆ London   ┆ 6000   │\n",
      "│ Charlie ┆ 35  ┆ Paris    ┆ 7000   │\n",
      "│ David   ┆ 40  ┆ Tokyo    ┆ 8000   │\n",
      "│ Eve     ┆ 45  ┆ Berlin   ┆ 9000   │\n",
      "└─────────┴─────┴──────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "    \"age\": [25, 30, 35, 40, 45],\n",
    "    \"city\": [\"New York\", \"London\", \"Paris\", \"Tokyo\", \"Berlin\"],\n",
    "    \"salary\": [5000, 6000, 7000, 8000, 9000]\n",
    "})\n",
    "print(df)\n",
    "\n",
    "# 也支持将数据写入常见的文件格式，比如 CSV、JSON 和 Parquet 等\n",
    "# df.write_csv(\"./output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6280b74b",
   "metadata": {},
   "source": [
    "### 查看 DataFrame  \n",
    "\n",
    "使用 `describe()` 方法来计算数据表中所有列的各种统计信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9, 5)\n",
      "┌────────────┬───────┬──────────┬────────┬────────────┐\n",
      "│ statistic  ┆ name  ┆ age      ┆ city   ┆ salary     │\n",
      "│ ---        ┆ ---   ┆ ---      ┆ ---    ┆ ---        │\n",
      "│ str        ┆ str   ┆ f64      ┆ str    ┆ f64        │\n",
      "╞════════════╪═══════╪══════════╪════════╪════════════╡\n",
      "│ count      ┆ 5     ┆ 5.0      ┆ 5      ┆ 5.0        │\n",
      "│ null_count ┆ 0     ┆ 0.0      ┆ 0      ┆ 0.0        │\n",
      "│ mean       ┆ null  ┆ 35.0     ┆ null   ┆ 7000.0     │\n",
      "│ std        ┆ null  ┆ 7.905694 ┆ null   ┆ 1581.13883 │\n",
      "│ min        ┆ Alice ┆ 25.0     ┆ Berlin ┆ 5000.0     │\n",
      "│ 25%        ┆ null  ┆ 30.0     ┆ null   ┆ 6000.0     │\n",
      "│ 50%        ┆ null  ┆ 35.0     ┆ null   ┆ 7000.0     │\n",
      "│ 75%        ┆ null  ┆ 40.0     ┆ null   ┆ 8000.0     │\n",
      "│ max        ┆ Eve   ┆ 45.0     ┆ Tokyo  ┆ 9000.0     │\n",
      "└────────────┴───────┴──────────┴────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989d6662",
   "metadata": {},
   "source": [
    "使用 `df.shape` 和 `df.columns` 属性查看 `DataFrame` 的形状和列名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd95475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5, 4)\n",
      "Columns: ['name', 'age', 'city', 'salary']\n"
     ]
    }
   ],
   "source": [
    "# 基本属性\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab44b0f",
   "metadata": {},
   "source": [
    "`df.schema` 返回一个包含所有列名及其对应数据类型的字典，可以用来查看数据表的结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0807d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema: Schema([('name', String), ('age', Int64), ('city', String), ('salary', Int64)])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Schema: {df.schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d956a10d",
   "metadata": {},
   "source": [
    "`df.dtypes` 属性返回一个仅包含所有列数据类型的列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d50fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types: [String, Int64, String, Int64]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data types: {df.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9db9dff",
   "metadata": {},
   "source": [
    "与 `Series` 类似，创建 `DataFrame` 时，`polars` 会自动推断其结构，可以使用 `schema` 和 `schema_overrides` 覆盖某些列的推理结果。  \n",
    "\n",
    "使用 `schema` 时，对于不指定覆盖名称的列，需要使用 `None` 表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010f2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬─────┐\n",
      "│ name   ┆ age │\n",
      "│ ---    ┆ --- │\n",
      "│ str    ┆ u8  │\n",
      "╞════════╪═════╡\n",
      "│ Alice  ┆ 27  │\n",
      "│ Ben    ┆ 39  │\n",
      "│ Chloe  ┆ 41  │\n",
      "│ Daniel ┆ 43  │\n",
      "└────────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "df0 = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Ben\", \"Chloe\", \"Daniel\"],\n",
    "        \"age\": [27, 39, 41, 43],\n",
    "    },\n",
    "    schema={\"name\": None, \"age\": pl.UInt8},\n",
    ")\n",
    "\n",
    "print(df0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed15d317",
   "metadata": {},
   "source": [
    "而 `schema_overrides` 参数会更加方便，因为它允许直接忽略不想覆盖的列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fd2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬─────┐\n",
      "│ name   ┆ age │\n",
      "│ ---    ┆ --- │\n",
      "│ str    ┆ u8  │\n",
      "╞════════╪═════╡\n",
      "│ Alice  ┆ 27  │\n",
      "│ Ben    ┆ 39  │\n",
      "│ Chloe  ┆ 41  │\n",
      "│ Daniel ┆ 43  │\n",
      "└────────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "df0 = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Ben\", \"Chloe\", \"Daniel\"],\n",
    "        \"age\": [27, 39, 41, 43],\n",
    "    },\n",
    "    schema_overrides={\"age\": pl.UInt8},\n",
    ")\n",
    "\n",
    "print(df0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8e81c3",
   "metadata": {},
   "source": [
    "`head()` 方法显示 `DataFrame` 的前 `n` 行。默认情况下，会显示前 `5` 行，但也可以指定想要显示的行数。\n",
    "\n",
    "`tail()` 方法用于返回 `DataFrame` 的最后 `n` 行，类似于 `pandas` 中的 `tail`。\n",
    "\n",
    "`sample()` 方法用于从 `DataFrame` 中随机抽取 `n` 行，默认不重复（除非指定允许重复）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9e8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head:\n",
      "shape: (2, 4)\n",
      "┌───────┬─────┬──────────┬────────┐\n",
      "│ name  ┆ age ┆ city     ┆ salary │\n",
      "│ ---   ┆ --- ┆ ---      ┆ ---    │\n",
      "│ str   ┆ i64 ┆ str      ┆ i64    │\n",
      "╞═══════╪═════╪══════════╪════════╡\n",
      "│ Alice ┆ 25  ┆ New York ┆ 5000   │\n",
      "│ Bob   ┆ 30  ┆ London   ┆ 6000   │\n",
      "└───────┴─────┴──────────┴────────┘\n",
      "Tail:\n",
      "shape: (2, 4)\n",
      "┌───────┬─────┬────────┬────────┐\n",
      "│ name  ┆ age ┆ city   ┆ salary │\n",
      "│ ---   ┆ --- ┆ ---    ┆ ---    │\n",
      "│ str   ┆ i64 ┆ str    ┆ i64    │\n",
      "╞═══════╪═════╪════════╪════════╡\n",
      "│ David ┆ 40  ┆ Tokyo  ┆ 8000   │\n",
      "│ Eve   ┆ 45  ┆ Berlin ┆ 9000   │\n",
      "└───────┴─────┴────────┴────────┘\n",
      "Sample:\n",
      "shape: (2, 4)\n",
      "┌───────┬─────┬────────┬────────┐\n",
      "│ name  ┆ age ┆ city   ┆ salary │\n",
      "│ ---   ┆ --- ┆ ---    ┆ ---    │\n",
      "│ str   ┆ i64 ┆ str    ┆ i64    │\n",
      "╞═══════╪═════╪════════╪════════╡\n",
      "│ Bob   ┆ 30  ┆ London ┆ 6000   │\n",
      "│ David ┆ 40  ┆ Tokyo  ┆ 8000   │\n",
      "└───────┴─────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"Head:\")\n",
    "print(df.head(2))\n",
    "print(\"Tail:\")\n",
    "print(df.tail(2))\n",
    "print(\"Sample:\")\n",
    "print(df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c52864",
   "metadata": {},
   "source": [
    "`glimpse` 是另一个用于展示数据表前几行值的方法，但其输出格式与 `head` 不同。在这里，输出中的每一行对应一个单独的列，这使得对更宽的数据表进行检查变得更加容易:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d462d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 5\n",
      "Columns: 4\n",
      "$ name   <str> 'Alice', 'Bob', 'Charlie', 'David', 'Eve'\n",
      "$ age    <i64> 25, 30, 35, 40, 45\n",
      "$ city   <str> 'New York', 'London', 'Paris', 'Tokyo', 'Berlin'\n",
      "$ salary <i64> 5000, 6000, 7000, 8000, 9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.glimpse(return_as_string=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf70e8",
   "metadata": {},
   "source": [
    "以下是 polars DataFrame 的常用功能表格，可以作为快速参考指南。\n",
    "\n",
    "| 方法名称 | 功能描述 | 示例代码 |\n",
    "|----------|----------|----------|\n",
    "| `shape` | 返回 DataFrame 的形状（行数，列数） | `df.shape` |\n",
    "| `columns` | 返回 DataFrame 的列名列表 | `df.columns` |\n",
    "| `dtypes` | 返回 DataFrame 各列的数据类型列表 | `df.dtypes` |\n",
    "| `schema` | 返回 DataFrame 的 schema（列名和数据类型的有序字典） | `df.schema` |\n",
    "| `head(n)` | 返回前 n 行数据（默认为 5） | `df.head(10)` |\n",
    "| `tail(n)` | 返回后 n 行数据（默认为 5） | `df.tail(10)` |\n",
    "| `describe` | 返回 DataFrame 的统计描述 | `df.describe()` |\n",
    "| `select` | 选择指定的列（可同时进行表达式计算） | `df.select(pl.col(\"a\"), pl.col(\"b\") * 2)` |\n",
    "| `with_columns` | 添加或修改列（类似于 `select` 但保留所有列） | `df.with_columns((pl.col(\"a\") * 2).alias(\"a_double\"))` |\n",
    "| `drop` | 删除指定的列 | `df.drop(\"a\", \"b\")` |\n",
    "| `rename` | 重命名列 | `df.rename({\"old_name\": \"new_name\"})` |\n",
    "| `filter` | 根据条件过滤行 | `df.filter(pl.col(\"a\") > 2)` |\n",
    "| `sort` | 根据列排序 | `df.sort(\"a\", descending=True)` |\n",
    "| `group_by` | 分组（返回 GroupBy 对象，可接着进行聚合操作） | `df.group_by(\"a\").agg(pl.col(\"b\").sum())` |\n",
    "| `join` | 连接另一个 DataFrame | `df.join(other_df, on=\"key\", how=\"inner\")` |\n",
    "| `concat` | 拼接另一个 DataFrame（垂直或水平） | `pl.concat([df1, df2])` |\n",
    "| `clone` | 创建 DataFrame 的深拷贝 | `df.clone()` |\n",
    "| `lazy` | 将 DataFrame 转换为 LazyFrame，用于惰性求值 | `df.lazy()` |\n",
    "| `collect` | 对 LazyFrame 执行计算并返回 DataFrame | `lazy_df.collect()` |\n",
    "| `write_csv` | 将 DataFrame 写入 CSV 文件 | `df.write_csv(\"output.csv\")` |\n",
    "| `write_parquet` | 将 DataFrame 写入 Parquet 文件 | `df.write_parquet(\"output.parquet\")` |\n",
    "| `write_json` | 将 DataFrame 写入 JSON 文件 | `df.write_json(\"output.json\")` |\n",
    "| `get_column` | 根据列名获取 Series | `df.get_column(\"a\")` |\n",
    "| `to_series` | 将 DataFrame 转换为 Series（如果只有一列） | `df.to_series()` |\n",
    "| `to_pandas` | 将 DataFrame 转换为 Pandas DataFrame | `df.to_pandas()` |\n",
    "| `to_numpy` | 将 DataFrame 转换为 NumPy 数组 | `df.to_numpy()` |\n",
    "| `to_dict` | 将 DataFrame 转换为字典 | `df.to_dict()` |\n",
    "| `to_records` | 将 DataFrame 转换为记录列表 | `df.to_records()` |\n",
    "| `is_empty` | 检查 DataFrame 是否为空 | `df.is_empty()` |\n",
    "| `null_count` | 返回每列的空值数量 | `df.null_count()` |\n",
    "| `unique` | 返回指定列的唯一值（去重） | `df.unique(subset=[\"a\"])` |\n",
    "| `sample` | 从 DataFrame 中随机采样 | `df.sample(n=5, fraction=None, with_replacement=False)` |\n",
    "| `fill_null` | 填充空值 | `df.fill_null(0)` |\n",
    "| `fill_nan` | 填充 NaN 值（如果列是浮点类型） | `df.fill_nan(0.0)` |\n",
    "| `pipe` | 链式调用用户自定义函数 | `df.pipe(lambda df: df.with_columns(pl.col(\"a\").alias(\"new_col\")))` |\n",
    "| `explode` | 将列表类型的列展开为多行 | `df.explode(\"list_col\")` |\n",
    "| `melt` | 将 DataFrame 从宽格式转换为长格式 | `df.melt(id_vars=\"id\", value_vars=[\"a\", \"b\"])` |\n",
    "| `pivot` | 将 DataFrame 从长格式转换为宽格式 | `df.pivot(index=\"id\", columns=\"category\", values=\"value\")` |\n",
    "| `with_row_index` | 添加行索引列 | `df.with_row_index(\"index\")` |\n",
    "| `clear` | 清空 DataFrame 中的数据，保留 schema | `df.clear()` |\n",
    "| `slice` | 按位置切片选择行 | `df.slice(10, 5)` |\n",
    "| `gather_every` | 每隔 n 行选择一行 | `df.gather_every(3)` |\n",
    "| `fold` | 对每行应用函数进行折叠操作 | `df.fold(lambda acc, x: acc + x, 0)` |\n",
    "| `row` | 按行索引获取一行数据 | `df.row(0)` |\n",
    "| `rows` | 将 DataFrame 转换为行迭代器 | `df.rows()` |\n",
    "| `iter_rows` | 迭代每一行（返回命名元组） | `df.iter_rows()` |\n",
    "| `partition_by` | 根据列值将 DataFrame 分割为多个 | `df.partition_by(\"category\")` |\n",
    "| `upsert` | 更新或插入数据（基于键） | `df.upsert(other_df, on=\"key\")` |\n",
    "| `interpolate` | 对数值列进行插值 | `df.interpolate()` |\n",
    "| `rolling` | 滚动窗口计算 | `df.rolling(index_column=\"date\", period=\"1d\")` |\n",
    "| `str` | 访问字符串列的方法 | `df.select(pl.col(\"name\").str.to_uppercase())` |\n",
    "| `dt` | 访问日期时间列的方法 | `df.select(pl.col(\"date\").dt.year())` |\n",
    "| `arr` | 访问数组列的方法 | `df.select(pl.col(\"list\").arr.lengths())` |\n",
    "\n",
    "**请注意：**\n",
    "\n",
    "1. 表达式导向：polars 的核心是表达式系统，大多数操作通过 `pl.col(\"column_name\")` 表达式完成\n",
    "2. 惰性执行：使用 `df.lazy()` 进入惰性模式，通过 `.collect()` 触发计算\n",
    "3. 不可变性：大多数操作返回新的 DataFrame，原始 DataFrame 不会被修改\n",
    "4. 链式调用：Polars 鼓励使用链式调用风格：\n",
    "   ```python\n",
    "   result = (df.lazy()\n",
    "            .filter(pl.col(\"age\") > 18)\n",
    "            .group_by(\"category\")\n",
    "            .agg(pl.col(\"value\").mean())\n",
    "            .sort(\"category\")\n",
    "            .collect())\n",
    "   ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08b0608",
   "metadata": {},
   "source": [
    "## 表达式（Expression）\n",
    "\n",
    "表达式（*Expression*）是 `polars` 中用于数据转换和计算的一种领域语言（*DSL*），允许以简洁的声明性语法定义对数据的操作，比一般的 Python 代码更清晰。\n",
    "\n",
    "`polars` 基于 *Expression* 语法提供高度优化的数据查询引擎，与后面介绍的执行环境（*Context*）一起，对确保 `polars` 代码的高可读性和高性能至关重要，正确理解和运用 *Expression* 和 *Context* 是使用 `polars` 的关键。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c6386",
   "metadata": {},
   "source": [
    "`polars` *Expression* 主要特色是用 `pl.col()` 方法来引用列名，用这样的列名组成计算表达式，而其实际数据在之后将表达式用于特定 `DataFrame` 时才会带入计算。\n",
    "\n",
    "这种对数据计算方案的延迟表示形式提供良好的模块化，灵活而易于复用。\n",
    "\n",
    "比如，我们可以定义一个计算人体 BMI 的 `polars` *Expression* 如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb38fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[(col(\"weight\")) / (col(\"height\").pow([dyn int: 2]))]"
      ],
      "text/plain": [
       "<Expr ['[(col(\"weight\")) / (col(\"heigh…'] at 0x272F77C8D50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.col(\"weight\") / (pl.col(\"height\") ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d2023",
   "metadata": {},
   "source": [
    "注意，`polars` 会将我们书写的 *Expression* 编译成一种语言无关的中间表示形式（*IR*），在实际执行时才会对其进行优化和计算。\n",
    "\n",
    "进一步的，为了便于管理和复用，可以用变量存储表达式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d4c264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(col(\"weight\")) / (col(\"height\").pow([dyn int: 2]))]\n"
     ]
    }
   ],
   "source": [
    "bmi_expr = pl.col(\"weight\") / (pl.col(\"height\") ** 2)\n",
    "print(bmi_expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c7d76f",
   "metadata": {},
   "source": [
    "## 执行环境（Context）\n",
    "\n",
    "如前所述，*Expression* 只是一个计算公式，在定义时并不会进行任何计算，实际进行计算需要一个执行环境（*Context*）。同一个 *Expression* 根据其 *Context* 不同，也会产生不同的结果。\n",
    "\n",
    "在本节中，我们将了解 `polars` 所提供的四种最常见的 *Context*，包括：`select`、`with_column`、`filter` 和 `group_by`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344afeb7",
   "metadata": {},
   "source": [
    "下面的一组例子都将使用下列 `DataFrame` 数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104ee68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌────────────────┬────────────┬────────┬────────┐\n",
      "│ name           ┆ birthdate  ┆ weight ┆ height │\n",
      "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str            ┆ date       ┆ f64    ┆ f64    │\n",
      "╞════════════════╪════════════╪════════╪════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
      "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
      "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
      "└────────────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice Archer\", \"Ben Brown\", \"Chloe Cooper\", \"Daniel Donovan\"],\n",
    "        \"birthdate\": [\n",
    "            date(1997, 1, 10),\n",
    "            date(1985, 2, 15),\n",
    "            date(1983, 3, 22),\n",
    "            date(1981, 4, 30),\n",
    "        ],\n",
    "        \"weight\": [57.9, 72.5, 53.6, 83.1],  # (kg)\n",
    "        \"height\": [1.56, 1.77, 1.65, 1.75],  # (m)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8a4c6",
   "metadata": {},
   "source": [
    "### select\n",
    "\n",
    "`select` 基于 *Expression* 来创建新的列并返回一个包含这些列的 `DataFrame`。这些列的创建逻辑可以非常灵活，可以是常量，可以是其他列通过 *Expression* 计算的结果，可以是在此基础上调用聚合函数的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "┌───────────┬───────────┬───────────────┐\n",
      "│ bmi       ┆ avg_bmi   ┆ ideal_max_bmi │\n",
      "│ ---       ┆ ---       ┆ ---           │\n",
      "│ f64       ┆ f64       ┆ i32           │\n",
      "╞═══════════╪═══════════╪═══════════════╡\n",
      "│ 23.791913 ┆ 23.438973 ┆ 25            │\n",
      "│ 23.141498 ┆ 23.438973 ┆ 25            │\n",
      "│ 19.687787 ┆ 23.438973 ┆ 25            │\n",
      "│ 27.134694 ┆ 23.438973 ┆ 25            │\n",
      "└───────────┴───────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    bmi=bmi_expr,\n",
    "    avg_bmi=bmi_expr.mean(),\n",
    "    ideal_max_bmi=25,\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3460d9e",
   "metadata": {},
   "source": [
    "在 `select` 中使用的表达式必须生成长度完全相同的 `Series`，或者是一个标量值（常数）。标量值会进行类似 `numpy` 广播操作的扩展处理，以与其他序列的长度相匹配。\n",
    "\n",
    "这种向量与标量之间运算时进行的广播操作也会在表达式中自动完成，例如下面这个表达式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 1)\n",
      "┌───────────┐\n",
      "│ deviation │\n",
      "│ ---       │\n",
      "│ f64       │\n",
      "╞═══════════╡\n",
      "│ 0.115645  │\n",
      "│ -0.097471 │\n",
      "│ -1.22912  │\n",
      "│ 1.210946  │\n",
      "└───────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(deviation=(bmi_expr - bmi_expr.mean()) / bmi_expr.std())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa609721",
   "metadata": {},
   "source": [
    "### with_columns\n",
    "\n",
    "`with_columns` 与 `select` 非常相似。这两者的主要区别在于：`with_columns` 会创建一个新的 `DataFrame` 对象，其中自动包含原 `DataFrame` 中的所有列以及根据其输入表达式生成的新列；而 `select` 生成的 `DataFrame` 仅包含由其输入表达式所选定的列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85604283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 7)\n",
      "┌────────────────┬────────────┬────────┬────────┬───────────┬───────────┬───────────────┐\n",
      "│ name           ┆ birthdate  ┆ weight ┆ height ┆ bmi       ┆ avg_bmi   ┆ ideal_max_bmi │\n",
      "│ ---            ┆ ---        ┆ ---    ┆ ---    ┆ ---       ┆ ---       ┆ ---           │\n",
      "│ str            ┆ date       ┆ f64    ┆ f64    ┆ f64       ┆ f64       ┆ i32           │\n",
      "╞════════════════╪════════════╪════════╪════════╪═══════════╪═══════════╪═══════════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   ┆ 23.791913 ┆ 23.438973 ┆ 25            │\n",
      "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   ┆ 23.141498 ┆ 23.438973 ┆ 25            │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   ┆ 19.687787 ┆ 23.438973 ┆ 25            │\n",
      "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   ┆ 27.134694 ┆ 23.438973 ┆ 25            │\n",
      "└────────────────┴────────────┴────────┴────────┴───────────┴───────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.with_columns(\n",
    "    bmi=bmi_expr,\n",
    "    avg_bmi=bmi_expr.mean(),\n",
    "    ideal_max_bmi=25,\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc95b7",
   "metadata": {},
   "source": [
    "### filter\n",
    "\n",
    "`filter` 会根据一个或多个表达式来筛选数据表中的行，可以输入多个表达式，这些表达式会被视为逻辑与（AND）关系来进行行筛选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2fcde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 4)\n",
      "┌───────────┬────────────┬────────┬────────┐\n",
      "│ name      ┆ birthdate  ┆ weight ┆ height │\n",
      "│ ---       ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str       ┆ date       ┆ f64    ┆ f64    │\n",
      "╞═══════════╪════════════╪════════╪════════╡\n",
      "│ Ben Brown ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "└───────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.filter(\n",
    "    pl.col(\"birthdate\").is_between(date(1982, 12, 31), date(1996, 1, 1)),\n",
    "    pl.col(\"height\") > 1.7,\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0603ac",
   "metadata": {},
   "source": [
    "### group_by & aggregations\n",
    "\n",
    "在 `group_by` 这一 *Context* 中，会根据表达式计算结果来对所有数据行进行分组，然后可以使用 `agg` 方法对每个分组应用一个或多个聚合函数来计算汇总统计信息。\n",
    "\n",
    "下面的例子对出生年份进行计算，按照十年份来分组，然后将同组的人名聚合到一个列表里，顺便可以留意 `alias()` 方法提供的便利："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f4040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "┌────────┬─────────────────────────────────┐\n",
      "│ decade ┆ name                            │\n",
      "│ ---    ┆ ---                             │\n",
      "│ i32    ┆ list[str]                       │\n",
      "╞════════╪═════════════════════════════════╡\n",
      "│ 1990   ┆ [\"Alice Archer\"]                │\n",
      "│ 1980   ┆ [\"Ben Brown\", \"Chloe Cooper\", … │\n",
      "└────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.group_by(\n",
    "    (pl.col(\"birthdate\").dt.year() // 10 * 10).alias(\"decade\"),\n",
    ").agg(pl.col(\"name\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a2540e",
   "metadata": {},
   "source": [
    "上面的例子中我们只指定了一个分组的列，我们当然也可以指定多个列来进行多级分组，比如下面的例子中先按出生年代分组，再按身高是否低于 1.7 米进行二次分组，仍然将同组的人名聚合成列表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8319060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 3)\n",
      "┌────────┬────────┬─────────────────────────────────┐\n",
      "│ decade ┆ short? ┆ name                            │\n",
      "│ ---    ┆ ---    ┆ ---                             │\n",
      "│ i32    ┆ bool   ┆ list[str]                       │\n",
      "╞════════╪════════╪═════════════════════════════════╡\n",
      "│ 1980   ┆ false  ┆ [\"Ben Brown\", \"Daniel Donovan\"… │\n",
      "│ 1980   ┆ true   ┆ [\"Chloe Cooper\"]                │\n",
      "│ 1990   ┆ true   ┆ [\"Alice Archer\"]                │\n",
      "└────────┴────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.group_by(\n",
    "    (pl.col(\"birthdate\").dt.year() // 10 * 10).alias(\"decade\"),\n",
    "    (pl.col(\"height\") < 1.7).alias(\"short?\"),\n",
    ").agg(pl.col(\"name\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b44fb",
   "metadata": {},
   "source": [
    "聚合表达式处理后生成的 `DataFrame` 中每个分组表达式和每个聚合表达式都会对应一个列，靠左侧是分组表达式，右侧是聚合表达式。\n",
    "\n",
    "下面的例子里在上个例子基础上增加了更多的聚合表达式（注意 `.name.prefix()` 方法的使用）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e42952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 7)\n",
      "┌────────┬────────┬─────────────────────────────────┬─────┬─────────┬────────────┬────────────┐\n",
      "│ decade ┆ short? ┆ name                            ┆ len ┆ tallest ┆ avg_weight ┆ avg_height │\n",
      "│ ---    ┆ ---    ┆ ---                             ┆ --- ┆ ---     ┆ ---        ┆ ---        │\n",
      "│ i32    ┆ bool   ┆ list[str]                       ┆ u32 ┆ f64     ┆ f64        ┆ f64        │\n",
      "╞════════╪════════╪═════════════════════════════════╪═════╪═════════╪════════════╪════════════╡\n",
      "│ 1990   ┆ true   ┆ [\"Alice Archer\"]                ┆ 1   ┆ 1.56    ┆ 57.9       ┆ 1.56       │\n",
      "│ 1980   ┆ true   ┆ [\"Chloe Cooper\"]                ┆ 1   ┆ 1.65    ┆ 53.6       ┆ 1.65       │\n",
      "│ 1980   ┆ false  ┆ [\"Ben Brown\", \"Daniel Donovan\"… ┆ 2   ┆ 1.77    ┆ 77.8       ┆ 1.76       │\n",
      "└────────┴────────┴─────────────────────────────────┴─────┴─────────┴────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.group_by(\n",
    "    (pl.col(\"birthdate\").dt.year() // 10 * 10).alias(\"decade\"),\n",
    "    (pl.col(\"height\") < 1.7).alias(\"short?\"),\n",
    ").agg(\n",
    "    pl.col(\"name\"),\n",
    "    pl.len(),\n",
    "    pl.col(\"height\").max().alias(\"tallest\"),\n",
    "    pl.col(\"weight\", \"height\").mean().name.prefix(\"avg_\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301173a2",
   "metadata": {},
   "source": [
    "## 惰性（Lazy）API\n",
    "\n",
    "`polars` *Expression* 支持两种运行模式：主动模式（Eager API）和惰性模式（Lazy API）。\n",
    "\n",
    "到目前为止的例子都使用了主动 API，在这种模式下，查询会立即执行。而在惰性模式中，只有在收集查询结果时才会对其进行评估。在很多情况下，将计算执行推迟到最后一刻能够带来显著的性能优势，这也是惰性 API 更受青睐的原因。\n",
    "\n",
    "下面通过一个示例来说明这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477fd7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "    \"age\": [25, 30, 35, 40, 45],\n",
    "    \"city\": [\"New York\", \"London\", \"Paris\", \"Tokyo\", \"Berlin\"],\n",
    "    \"salary\": [5000, 6000, 7000, 8000, 9000]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a497750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 2)\n",
      "┌────────┬────────┐\n",
      "│ city   ┆ salary │\n",
      "│ ---    ┆ ---    │\n",
      "│ str    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ Tokyo  ┆ 8000.0 │\n",
      "│ Berlin ┆ 9000.0 │\n",
      "│ Paris  ┆ 7000.0 │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df.filter(pl.col(\"age\") > 30)\n",
    "df_agg = df_filtered.group_by(\"city\").agg(pl.col(\"salary\").mean())\n",
    "print(df_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12618192",
   "metadata": {},
   "source": [
    "在上面的代码中，我们使用主动 API 来：\n",
    "- 读取数据\n",
    "- 过滤年龄大于 `30` 的记录\n",
    "- 按城市分组并计算平均薪资 \n",
    "\n",
    "这每一步操作都会立即执行，并返回中间结果，这可能会造成浪费，因为前面的步骤可能会加载或处理后面用不到的数据，如果我们改为使用**惰性API**，它就会等到所有步骤都定义完毕之后再进行优化和执行，那么查询引擎就能规划更多的优化，比如：\n",
    "- 谓词前置：在读取数据集时尽早应用过滤条件，这样就只读取年龄大于 `30` 的行；\n",
    "- 投影前置：在读取数据集时仅选择所需的列，从而无需加载额外的列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe23111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 2)\n",
      "┌────────┬────────┐\n",
      "│ city   ┆ salary │\n",
      "│ ---    ┆ ---    │\n",
      "│ str    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ Berlin ┆ 9000.0 │\n",
      "│ Tokyo  ┆ 8000.0 │\n",
      "│ Paris  ┆ 7000.0 │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "q = (\n",
    "    pl.scan_csv(\"assets/output.csv\")  \n",
    "    .filter(pl.col(\"age\") > 30)  \n",
    "    .group_by(\"city\")  \n",
    "    .agg(pl.col(\"salary\").mean())  \n",
    ")\n",
    "\n",
    "df = q.collect()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49950031",
   "metadata": {},
   "source": [
    "简单说，就是把数据从加载到处理的过程定义在一个队列里，然后使用 `collect()` 方法来一次性批处理优化执行，这样 `polars` 就能对整个查询进行全局优化，显著减轻内存和 CPU 的负担，从而能够将更大的数据集存储在内存中并更快地进行处理，处理的数据集越大，效果越明显。\n",
    "\n",
    "这些优化都是自动完成的，无需用户干预，是不是很棒？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de25959",
   "metadata": {},
   "source": [
    "一般来说，在大数据量的生产环境中应优先使用惰性 API，除非我们对中间结果感兴趣，或者正在进行探索性研究并且还不清楚最终查询结果是什么样子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96da9ac9",
   "metadata": {},
   "source": [
    "### 流式处理（Steaming）\n",
    "\n",
    "惰性 API 的另一个优点是它允许以流式方式执行查询，与一次性处理所有数据不同，`polars` 可以分批执行查询，使得当数据集无法全部装入内存时也能处理，此外，流式引擎的性能也更出色。\n",
    "\n",
    "要在使用流式模式，只要在代码中设置 `engine='streaming'` 参数即可，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd33f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (\n",
    "    pl.scan_csv(\"assets/output.csv\")  \n",
    "    .filter(pl.col(\"age\") > 30)  \n",
    "    .group_by(\"city\")  \n",
    "    .agg(pl.col(\"salary\").mean())  \n",
    ")\n",
    "\n",
    "df = q.collect(engine=\"streaming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d474c3cd",
   "metadata": {},
   "source": [
    "## 读写数据\n",
    "\n",
    "`polars` 支持读取和写入常见的文件（例如 *CSV*、*JSON*、*Parquet*）、云存储（*S3*、*Azure Blob*、*BigQuery*）以及关系型数据库（例如 *PostgresSQL*、*MySQL* ）等数据源。\n",
    "\n",
    "在下面的例子里，使用 `read_csv()` 方法读取 CSV 文件，使用 `write_csv()` 方法写入 CSV 文件，同样的方法也适用于其他格式的文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7e2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────┬─────┬──────────┬────────┐\n",
      "│ name    ┆ age ┆ city     ┆ salary │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---    │\n",
      "│ str     ┆ i64 ┆ str      ┆ i64    │\n",
      "╞═════════╪═════╪══════════╪════════╡\n",
      "│ Alice   ┆ 25  ┆ New York ┆ 5000   │\n",
      "│ Bob     ┆ 30  ┆ London   ┆ 6000   │\n",
      "│ Charlie ┆ 35  ┆ Paris    ┆ 7000   │\n",
      "│ David   ┆ 40  ┆ Tokyo    ┆ 8000   │\n",
      "│ Eve     ┆ 45  ┆ Berlin   ┆ 9000   │\n",
      "└─────────┴─────┴──────────┴────────┘\n",
      "shape: (3, 2)\n",
      "┌────────┬────────┐\n",
      "│ city   ┆ salary │\n",
      "│ ---    ┆ ---    │\n",
      "│ str    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ Tokyo  ┆ 8000.0 │\n",
      "│ Berlin ┆ 9000.0 │\n",
      "│ Paris  ┆ 7000.0 │\n",
      "└────────┴────────┘\n",
      "shape: (3, 2)\n",
      "┌────────┬────────┐\n",
      "│ city   ┆ salary │\n",
      "│ ---    ┆ ---    │\n",
      "│ str    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ Tokyo  ┆ 8000.0 │\n",
      "│ Berlin ┆ 9000.0 │\n",
      "│ Paris  ┆ 7000.0 │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# 读写 CSV 文件\n",
    "# df.write_csv(\"output.csv\")\n",
    "df_from_csv = pl.read_csv(\"assets/output.csv\")\n",
    "print(df_from_csv)\n",
    "\n",
    "# 读写 Parquet 文件（更高效）\n",
    "# df.write_parquet(\"output.parquet\")\n",
    "df_from_parquet = pl.read_parquet(\"assets/output.parquet\")\n",
    "print(df_from_parquet)\n",
    "\n",
    "# 读写 JSON 文件\n",
    "# df.write_json(\"output.json\")\n",
    "df_from_json = pl.read_json(\"assets/output.json\")\n",
    "print(df_from_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f4700",
   "metadata": {},
   "source": [
    "## 与 pandas 对比\n",
    "\n",
    "### 语法和用法\n",
    "\n",
    "`polars` 的语法与 `pandas` 比较接近，但在某些方面有更简洁高效的设计，比如表达式（*Expression*）和惰性 API。实际上，`polars` 的很多设计灵感都来源于 `pandas`，但在性能和内存效率方面做了大量优化，而 `pandas` 的最新版本也在学习一些 `polars` 的设计理念。\n",
    "\n",
    "### 性能\n",
    "\n",
    "`polars` 在性能方面通常优于 `pandas`，尤其是在处理大规模数据集时。其多线程并行计算和内存效率使得它在执行复杂查询和数据转换时表现出色。\n",
    "\n",
    "下面是简单的速度与内存占用对比："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ad0a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polars 处理时间: 0.017 秒\n",
      "pandas 处理时间: 0.057 秒\n",
      "速度提升: 3.3 倍\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# 创建大型数据集\n",
    "n_rows = 1_000_000\n",
    "data = {\n",
    "    \"x\": np.random.randn(n_rows),\n",
    "    \"y\": np.random.randn(n_rows),\n",
    "    \"category\": np.random.choice([\"A\", \"B\", \"C\"], n_rows)\n",
    "}\n",
    "\n",
    "# 创建 polars DataFrame\n",
    "df_polars = pl.DataFrame(data)\n",
    "\n",
    "# 创建 pandas DataFrame\n",
    "df_pandas = pd.DataFrame(data)\n",
    "\n",
    "# 测量聚合操作的时间\n",
    "start_time = time.time()\n",
    "result_polars = df_polars.group_by(\"category\").agg(pl.col(\"x\").mean())\n",
    "end_time = time.time()\n",
    "polars_time = end_time - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "result_pandas = df_pandas.groupby(\"category\")[\"x\"].mean()\n",
    "end_time = time.time()\n",
    "pandas_time = end_time - start_time\n",
    "\n",
    "print(f\"polars 处理时间: {polars_time:.3f} 秒\")\n",
    "print(f\"pandas 处理时间: {pandas_time:.3f} 秒\")\n",
    "print(f\"速度提升: {pandas_time/polars_time:.1f} 倍\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e642ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polars 内存使用: 0.00 MB\n",
      "pandas 内存使用: 70.57 MB\n",
      "内存节省: 1321431.5 倍\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "polars_memory = sys.getsizeof(df_polars)\n",
    "pandas_memory = sys.getsizeof(df_pandas)\n",
    "\n",
    "print(f\"polars 内存使用: {polars_memory / 1024 / 1024:.2f} MB\")\n",
    "print(f\"pandas 内存使用: {pandas_memory / 1024 / 1024:.2f} MB\")\n",
    "print(f\"内存节省: {pandas_memory/polars_memory:.1f} 倍\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef2a9b",
   "metadata": {},
   "source": [
    "### 互操作\n",
    "\n",
    "`polars` 可以很方便地与 `pandas` 进行互操作，但需要安装 `pyarrow` 库：\n",
    "\n",
    "```shell\n",
    "pip install pyarrow\n",
    "```\n",
    "\n",
    "然后就可以运行下面的例子了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb61ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     city  salary\n",
      "0  Berlin  9000.0\n",
      "1   Paris  7000.0\n",
      "2   Tokyo  8000.0\n",
      "<class 'polars.dataframe.frame.DataFrame'>\n",
      "shape: (3, 2)\n",
      "┌────────┬────────┐\n",
      "│ city   ┆ salary │\n",
      "│ ---    ┆ ---    │\n",
      "│ str    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ Berlin ┆ 9000.0 │\n",
      "│ Paris  ┆ 7000.0 │\n",
      "│ Tokyo  ┆ 8000.0 │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# polars DataFrame → pandas DataFrame\n",
    "pandas_df = df.to_pandas()\n",
    "print(type(pandas_df))\n",
    "print(pandas_df.head())\n",
    "\n",
    "# vice versa: pandas DataFrame → polars DataFrame\n",
    "df_from_pandas = pl.from_pandas(pandas_df)\n",
    "print(type(df_from_pandas))\n",
    "print(df_from_pandas.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8178c5b",
   "metadata": {},
   "source": [
    "### 选型\n",
    "\n",
    "`polars` 在以下场景中表现尤为出色：\n",
    "- 处理大型数据集（GB 级别或更大）\n",
    "- 需要最佳性能\n",
    "- 内存受限的环境\n",
    "- 需要多线程处理\n",
    "\n",
    "而下面的场景可能更适合使用 `pandas`：\n",
    "- 需要与丰富的 `pandas` 生态系统集成\n",
    "- 使用许多专门的数据分析库\n",
    "- 处理小型数据集且开发速度更重要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf70d2f",
   "metadata": {},
   "source": [
    "## 进阶应用示例\n",
    "\n",
    "### 表达式 API\n",
    "\n",
    "一些 `polars` 表达式 *Expression* 的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d01020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "    \"age\": [25, 30, 35, 40, 45],\n",
    "    \"city\": [\"New York\", \"London\", \"Paris\", \"Tokyo\", \"Berlin\"],\n",
    "    \"salary\": [5000, 6000, 7000, 8000, 9000]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8219c33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌─────────┬─────┬────────┬────────────────┬─────────────────┐\n",
      "│ name    ┆ age ┆ salary ┆ salary_per_age ┆ adjusted_salary │\n",
      "│ ---     ┆ --- ┆ ---    ┆ ---            ┆ ---             │\n",
      "│ str     ┆ i64 ┆ i64    ┆ f64            ┆ f64             │\n",
      "╞═════════╪═════╪════════╪════════════════╪═════════════════╡\n",
      "│ Alice   ┆ 25  ┆ 5000   ┆ 200.0          ┆ 5000.0          │\n",
      "│ Bob     ┆ 30  ┆ 6000   ┆ 200.0          ┆ 6000.0          │\n",
      "│ Charlie ┆ 35  ┆ 7000   ┆ 200.0          ┆ 7700.0          │\n",
      "│ David   ┆ 40  ┆ 8000   ┆ 200.0          ┆ 8800.0          │\n",
      "│ Eve     ┆ 45  ┆ 9000   ┆ 200.0          ┆ 9900.0          │\n",
      "└─────────┴─────┴────────┴────────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# 使用表达式进行复杂操作\n",
    "result = df.select([\n",
    "    pl.col(\"name\"),\n",
    "    pl.col(\"age\"),\n",
    "    pl.col(\"salary\"),\n",
    "    (pl.col(\"salary\") / pl.col(\"age\")).alias(\"salary_per_age\"),\n",
    "    pl.when(pl.col(\"age\") > 30)\n",
    "      .then(pl.col(\"salary\") * 1.1)\n",
    "      .otherwise(pl.col(\"salary\"))\n",
    "      .alias(\"adjusted_salary\")\n",
    "])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005bd82",
   "metadata": {},
   "source": [
    "### 时间序列处理\n",
    "\n",
    "`polars` 还内置了一些常用的针对时间序列数据的处理方法。例如重采样、时间窗口和滑动窗口计算等操作。下面是一个简单的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33379ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 2)\n",
      "┌────────────┬───────┐\n",
      "│ date       ┆ value │\n",
      "│ ---        ┆ ---   │\n",
      "│ date       ┆ i64   │\n",
      "╞════════════╪═══════╡\n",
      "│ 2023-01-01 ┆ 1     │\n",
      "│ 2023-01-02 ┆ 2     │\n",
      "│ 2023-01-03 ┆ 3     │\n",
      "│ 2023-01-04 ┆ 4     │\n",
      "│ 2023-01-05 ┆ 5     │\n",
      "│ 2023-01-06 ┆ 6     │\n",
      "│ 2023-01-07 ┆ 7     │\n",
      "│ 2023-01-08 ┆ 8     │\n",
      "│ 2023-01-09 ┆ 9     │\n",
      "│ 2023-01-10 ┆ 10    │\n",
      "└────────────┴───────┘\n",
      "shape: (10, 5)\n",
      "┌────────────┬───────┬──────┬──────┬──────────────┐\n",
      "│ date       ┆ value ┆ diff ┆ lag  ┆ rolling_mean │\n",
      "│ ---        ┆ ---   ┆ ---  ┆ ---  ┆ ---          │\n",
      "│ date       ┆ i64   ┆ i64  ┆ i64  ┆ f64          │\n",
      "╞════════════╪═══════╪══════╪══════╪══════════════╡\n",
      "│ 2023-01-01 ┆ 1     ┆ null ┆ null ┆ null         │\n",
      "│ 2023-01-02 ┆ 2     ┆ 1    ┆ 1    ┆ null         │\n",
      "│ 2023-01-03 ┆ 3     ┆ 1    ┆ 2    ┆ 2.0          │\n",
      "│ 2023-01-04 ┆ 4     ┆ 1    ┆ 3    ┆ 3.0          │\n",
      "│ 2023-01-05 ┆ 5     ┆ 1    ┆ 4    ┆ 4.0          │\n",
      "│ 2023-01-06 ┆ 6     ┆ 1    ┆ 5    ┆ 5.0          │\n",
      "│ 2023-01-07 ┆ 7     ┆ 1    ┆ 6    ┆ 6.0          │\n",
      "│ 2023-01-08 ┆ 8     ┆ 1    ┆ 7    ┆ 7.0          │\n",
      "│ 2023-01-09 ┆ 9     ┆ 1    ┆ 8    ┆ 8.0          │\n",
      "│ 2023-01-10 ┆ 10    ┆ 1    ┆ 9    ┆ 9.0          │\n",
      "└────────────┴───────┴──────┴──────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# 创建时间序列数据\n",
    "date_ranges = pl.date_range(\n",
    "    start=pl.datetime(2023, 1, 1),\n",
    "    end=pl.datetime(2023, 1, 10),\n",
    "    interval=\"1d\",\n",
    "    eager=True\n",
    ")\n",
    "\n",
    "ts_df = pl.DataFrame({\n",
    "    \"date\": date_ranges,\n",
    "    \"value\": range(1, 11)\n",
    "})\n",
    "print(ts_df)\n",
    "\n",
    "# 时间序列操作\n",
    "ts_result = ts_df.with_columns([\n",
    "    pl.col(\"value\").diff().alias(\"diff\"),\n",
    "    pl.col(\"value\").shift(1).alias(\"lag\"),\n",
    "    pl.col(\"value\").rolling_mean(window_size=3).alias(\"rolling_mean\")\n",
    "])\n",
    "print(ts_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9248451",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "`polars` 是一个强大且高效的数据处理库，具有以下优势：\n",
    "- 出色的性能，尤其适合处理大型数据集\n",
    "- 内存效率高，支持惰性执行\n",
    "- 丰富的数据操作功能\n",
    "- 良好的生态系统集成\n",
    "\n",
    "对于需要处理大规模数据的应用场景，`polars` 是一个很好的选择。对于熟悉 `pandas` 的用户，`polars` 的学习曲线相对平滑，大部分概念和操作都是相通的。\n",
    "\n",
    "如果希望了解更多详细信息和高级用法，可以参考 `polars` 的[官方文档](https://pola.rs/)。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
