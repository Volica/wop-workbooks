{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3288e40f",
   "metadata": {},
   "source": [
    "# `polars` 学习簿\n",
    "\n",
    "`polars` 是一个现代化、高性能的 `DataFrame` 数据处理库，专为处理大规模数据集而设计。它采用了全新的架构理念，在 `Rust` 语言基础上构建，通过 `PyO3` 提供 `Python` 接口，完美结合了系统级语言的性能优势和脚本语言的易用性。\n",
    "\n",
    "不同于传统的 `pandas` 库，`polars` 从底层设计就专注于并行计算和内存效率，采用了`Apache Arrow` 作为内存数据格式，实现了在多核处理器上的高效并行操作。其名称 \"polars\" 寓意着像北极星一样为数据科学家指引方向，提供高性能的数据处理解决方案。\n",
    "\n",
    "以下是`polars`的核心架构与技术特点：\n",
    "\n",
    "- **高性能计算引擎**：多线程并行、向量化(SIMD)执行、智能查询优化及高效内存管理\n",
    "- **数据类型系统**：严格类型系统，支持空值安全处理、时间序列优化及嵌套数据类型\n",
    "- **执行模式**：支持即时执行、惰性执行及自动选择的混合执行策略\n",
    "- **数据读写能力**：多格式支持(CSV/Parquet等)、大数据分块处理、云存储集成及数据库连接\n",
    "- **数据处理操作**：提供表达式API、聚合操作、多种连接方式及专业时间序列处理功能\n",
    "- **数据可视化集成**：与主流可视化库无缝集成，支持直接绘图和`Jupyter`交互探索\n",
    "- **与Python生态集成**：支持与`pandas`、`NumPy`互操作，以及机器学习框架协同工作\n",
    "\n",
    "`polars` 代表了数据处理库的新一代发展方向，将性能、内存效率和易用性完美结合。无论您是数据科学家、分析师还是工程师，`polars` 都能为您提供高效、可靠的数据处理解决方案。通过本工作簿的学习，您将掌握 `polars` 的核心概念和高级功能，并能够在实际项目中应用这些知识，提升数据处理效率和分析能力。\n",
    "\n",
    "本学习材料将循序渐进地引导您掌握 `polars`，从基础操作到高级技巧，并通过与 `pandas` 的对比帮助您理解两者的异同和适用场景。让我们开始这段高效数据处理的学习之旅吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8be6cfb",
   "metadata": {},
   "source": [
    "## 准备\n",
    "你可以通过 pip来安装 `polars`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd7bc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.33.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ysql-connector-python (c:\\Users\\DELL\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ysql-connector-python (c:\\Users\\DELL\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ysql-connector-python (c:\\Users\\DELL\\anaconda3\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5281e",
   "metadata": {},
   "source": [
    "然后就可以在你的程序中引入 `polars`库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf83e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d693c",
   "metadata": {},
   "source": [
    "下面所有的操作都假定你已经完成了上面两步。\n",
    "接下来，让我们从基础着手认识`polars`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92a661",
   "metadata": {},
   "source": [
    "## 核心数据类型与结构\n",
    "###     Series \n",
    "`Series`是 `polars`中的一维数据结构，类似于 `pandas`的 `Series`或 `numpy`的 `ndarray`。  \n",
    "在一个 `Series` 中，所有元素都具有相同的数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b7f207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3,)\n",
      "Series: 'ages' [i64]\n",
      "[\n",
      "\t25\n",
      "\t30\n",
      "\t35\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# 创建 Series\n",
    "s = pl.Series(\"ages\", [25, 30, 35])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71e251b",
   "metadata": {},
   "source": [
    "在创建序列时，`polars` 会根据提供的值来推断数据类型。你也可以指定具体的数据类型来覆盖这种推断机制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a61c2f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64 UInt64\n"
     ]
    }
   ],
   "source": [
    "s1 = pl.Series(\"ints\", [1, 2, 3, 4, 5])\n",
    "s2 = pl.Series(\"uints\", [1, 2, 3, 4, 5], dtype=pl.UInt64)\n",
    "print(s1.dtype, s2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc1677",
   "metadata": {},
   "source": [
    "`name`获取数组名,`dtype` 则表示数组的数据类型."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd715552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: ages\n",
      "Length: 3\n",
      "Data type: Int64\n",
      "Values: [25, 30, 35]\n"
     ]
    }
   ],
   "source": [
    "# 基本属性\n",
    "print(f\"Name: {s.name}\")\n",
    "print(f\"Length: {len(s)}\")\n",
    "print(f\"Data type: {s.dtype}\")\n",
    "print(f\"Values: {s.to_list()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d70cd4",
   "metadata": {},
   "source": [
    "`series`可直接求最大值，最小值，平均值和总和。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b70f6311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 35\n",
      "Min: 25\n",
      "Mean: 30.0\n",
      "Sum: 90\n"
     ]
    }
   ],
   "source": [
    "# 基本操作\n",
    "print(f\"Max: {s.max()}\")\n",
    "print(f\"Min: {s.min()}\")\n",
    "print(f\"Mean: {s.mean()}\") \n",
    "print(f\"Sum: {s.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f27a0a7",
   "metadata": {},
   "source": [
    "`Series`支持向量间的基本运算，比如加减乘除等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e95cce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pl.Series(\"temp\", [2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c147c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3,)\n",
      "Series: 'ages' [i64]\n",
      "[\n",
      "\t27\n",
      "\t33\n",
      "\t39\n",
      "]\n",
      "shape: (3,)\n",
      "Series: 'ages' [i64]\n",
      "[\n",
      "\t23\n",
      "\t27\n",
      "\t31\n",
      "]\n",
      "shape: (3,)\n",
      "Series: 'ages' [i64]\n",
      "[\n",
      "\t50\n",
      "\t90\n",
      "\t140\n",
      "]\n",
      "shape: (3,)\n",
      "Series: 'ages' [f64]\n",
      "[\n",
      "\t12.5\n",
      "\t10.0\n",
      "\t8.75\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# 向量化操作\n",
    "print(s + x)\n",
    "print(s - x)\n",
    "print(s * x)\n",
    "print(s / x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7572948",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "`DataFrame`是 `polars`的核心数据结构，它是一个二维表格，类似于 `pandas`的 `DataFrame`或关系数据库中的表。\n",
    "\n",
    "#### 创建 DataFrame\n",
    "\n",
    "支持从多种数据源创建 `DataFrame`，比如列表、字典或直接读取文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fed3eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────┬─────┬──────────┬────────┐\n",
      "│ name    ┆ age ┆ city     ┆ salary │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---    │\n",
      "│ str     ┆ i64 ┆ str      ┆ i64    │\n",
      "╞═════════╪═════╪══════════╪════════╡\n",
      "│ Alice   ┆ 25  ┆ New York ┆ 5000   │\n",
      "│ Bob     ┆ 30  ┆ London   ┆ 6000   │\n",
      "│ Charlie ┆ 35  ┆ Paris    ┆ 7000   │\n",
      "│ David   ┆ 40  ┆ Tokyo    ┆ 8000   │\n",
      "│ Eve     ┆ 45  ┆ Berlin   ┆ 9000   │\n",
      "└─────────┴─────┴──────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# 从字典创建 DataFrame\n",
    "df = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "    \"age\": [25, 30, 35, 40, 45],\n",
    "    \"city\": [\"New York\", \"London\", \"Paris\", \"Tokyo\", \"Berlin\"],\n",
    "    \"salary\": [5000, 6000, 7000, 8000, 9000]\n",
    "})\n",
    "print(df)\n",
    "# df.write_csv(\"./output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6280b74b",
   "metadata": {},
   "source": [
    "### 查看DataFrame  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a806205",
   "metadata": {},
   "source": [
    "使用`describe`函数来计算数据框中所有列的汇总统计信息:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7159b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9, 5)\n",
      "┌────────────┬───────┬──────────┬────────┬────────────┐\n",
      "│ statistic  ┆ name  ┆ age      ┆ city   ┆ salary     │\n",
      "│ ---        ┆ ---   ┆ ---      ┆ ---    ┆ ---        │\n",
      "│ str        ┆ str   ┆ f64      ┆ str    ┆ f64        │\n",
      "╞════════════╪═══════╪══════════╪════════╪════════════╡\n",
      "│ count      ┆ 5     ┆ 5.0      ┆ 5      ┆ 5.0        │\n",
      "│ null_count ┆ 0     ┆ 0.0      ┆ 0      ┆ 0.0        │\n",
      "│ mean       ┆ null  ┆ 35.0     ┆ null   ┆ 7000.0     │\n",
      "│ std        ┆ null  ┆ 7.905694 ┆ null   ┆ 1581.13883 │\n",
      "│ min        ┆ Alice ┆ 25.0     ┆ Berlin ┆ 5000.0     │\n",
      "│ 25%        ┆ null  ┆ 30.0     ┆ null   ┆ 6000.0     │\n",
      "│ 50%        ┆ null  ┆ 35.0     ┆ null   ┆ 7000.0     │\n",
      "│ 75%        ┆ null  ┆ 40.0     ┆ null   ┆ 8000.0     │\n",
      "│ max        ┆ Eve   ┆ 45.0     ┆ Tokyo  ┆ 9000.0     │\n",
      "└────────────┴───────┴──────────┴────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989d6662",
   "metadata": {},
   "source": [
    "使用`df.shape`和`df.columns`属性查看DataFrame的形状和列名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd95475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5, 4)\n",
      "Columns: ['name', 'age', 'city', 'salary']\n"
     ]
    }
   ],
   "source": [
    "# 基本属性\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab44b0f",
   "metadata": {},
   "source": [
    "`df.schema`返回一个包含所有列名及其对应数据类型的字典，可以使用`schema`\n",
    "来查看数据框的结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe0807d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema: Schema([('name', String), ('age', Int64), ('city', String), ('salary', Int64)])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Schema: {df.schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d956a10d",
   "metadata": {},
   "source": [
    "而 `df.dtypes`返回一个仅包含所有列数据类型的列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "616d50fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types: [String, Int64, String, Int64]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data types: {df.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9db9dff",
   "metadata": {},
   "source": [
    "与`Series`类似，创建`DataFrame`时，`polars`会自动推断其结构可以使用`schema`和`schema_overrides`覆盖某些列的推理结果。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694a9d03",
   "metadata": {},
   "source": [
    "使用`schema`时，对于不指定覆盖名称的列，需要使用None表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0010f2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬─────┐\n",
      "│ name   ┆ age │\n",
      "│ ---    ┆ --- │\n",
      "│ str    ┆ u8  │\n",
      "╞════════╪═════╡\n",
      "│ Alice  ┆ 27  │\n",
      "│ Ben    ┆ 39  │\n",
      "│ Chloe  ┆ 41  │\n",
      "│ Daniel ┆ 43  │\n",
      "└────────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "df0 = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Ben\", \"Chloe\", \"Daniel\"],\n",
    "        \"age\": [27, 39, 41, 43],\n",
    "    },\n",
    "    schema={\"name\": None, \"age\": pl.UInt8},\n",
    ")\n",
    "\n",
    "print(df0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed15d317",
   "metadata": {},
   "source": [
    "而`schema overrides`会更加方便，因为它允许直接忽略不想覆盖的列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a5fd2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌────────┬─────┐\n",
      "│ name   ┆ age │\n",
      "│ ---    ┆ --- │\n",
      "│ str    ┆ u8  │\n",
      "╞════════╪═════╡\n",
      "│ Alice  ┆ 27  │\n",
      "│ Ben    ┆ 39  │\n",
      "│ Chloe  ┆ 41  │\n",
      "│ Daniel ┆ 43  │\n",
      "└────────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "df0 = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Ben\", \"Chloe\", \"Daniel\"],\n",
    "        \"age\": [27, 39, 41, 43],\n",
    "    },\n",
    "    schema_overrides={\"age\": pl.UInt8},\n",
    ")\n",
    "\n",
    "print(df0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8e81c3",
   "metadata": {},
   "source": [
    "`head`函数头部显示`DataFrame`的前几行。\n",
    "默认情况下，会显示前 5 行，但也可以指定想要显示的行数。  \n",
    "`tail`函数用于返回`DataFrame`的最后n行，类似于`pandas`中的`tail`。  \n",
    "`sample`函数用于从`DataFrame`中随机抽取n行，不重复（默认情况下，除非指定允许重复）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94a9e8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head:\n",
      "shape: (2, 4)\n",
      "┌───────┬─────┬──────────┬────────┐\n",
      "│ name  ┆ age ┆ city     ┆ salary │\n",
      "│ ---   ┆ --- ┆ ---      ┆ ---    │\n",
      "│ str   ┆ i64 ┆ str      ┆ i64    │\n",
      "╞═══════╪═════╪══════════╪════════╡\n",
      "│ Alice ┆ 25  ┆ New York ┆ 5000   │\n",
      "│ Bob   ┆ 30  ┆ London   ┆ 6000   │\n",
      "└───────┴─────┴──────────┴────────┘\n",
      "Tail:\n",
      "shape: (2, 4)\n",
      "┌───────┬─────┬────────┬────────┐\n",
      "│ name  ┆ age ┆ city   ┆ salary │\n",
      "│ ---   ┆ --- ┆ ---    ┆ ---    │\n",
      "│ str   ┆ i64 ┆ str    ┆ i64    │\n",
      "╞═══════╪═════╪════════╪════════╡\n",
      "│ David ┆ 40  ┆ Tokyo  ┆ 8000   │\n",
      "│ Eve   ┆ 45  ┆ Berlin ┆ 9000   │\n",
      "└───────┴─────┴────────┴────────┘\n",
      "Sample:\n",
      "shape: (2, 4)\n",
      "┌─────────┬─────┬────────┬────────┐\n",
      "│ name    ┆ age ┆ city   ┆ salary │\n",
      "│ ---     ┆ --- ┆ ---    ┆ ---    │\n",
      "│ str     ┆ i64 ┆ str    ┆ i64    │\n",
      "╞═════════╪═════╪════════╪════════╡\n",
      "│ Bob     ┆ 30  ┆ London ┆ 6000   │\n",
      "│ Charlie ┆ 35  ┆ Paris  ┆ 7000   │\n",
      "└─────────┴─────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# 查看数据\n",
    "print(\"Head:\")\n",
    "print(df.head(2))\n",
    "print(\"Tail:\")\n",
    "print(df.tail(2))\n",
    "print(\"Sample:\")\n",
    "print(df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c52864",
   "metadata": {},
   "source": [
    "`glimpse`是另一个用于展示数据框前几行值的函数，但其输出格式与`head`不同。在这里，输出中的每一行对应一个单独的列，这使得对更宽的数据框进行检查变得更加容易:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1d462d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 5\n",
      "Columns: 4\n",
      "$ name   <str> 'Alice', 'Bob', 'Charlie', 'David', 'Eve'\n",
      "$ age    <i64> 25, 30, 35, 40, 45\n",
      "$ city   <str> 'New York', 'London', 'Paris', 'Tokyo', 'Berlin'\n",
      "$ salary <i64> 5000, 6000, 7000, 8000, 9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.glimpse(return_as_string=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08b0608",
   "metadata": {},
   "source": [
    "## 表达式(Expression)\n",
    "`polars` 已经开发出了自己的特定领域语言(DSL)来处理数据转换。这种语言非常易于使用，并且能够处理复杂的查询，同时这些查询仍能保持较高的可读性。  \n",
    "这里将要介绍的表达式(Expression)和后续介绍的执行环境(Context)对于实现这种可读性非常重要，同时还能让`polars` 查询引擎优化查询，使其运行速度尽可能快。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c6386",
   "metadata": {},
   "source": [
    "表达式是一种对数据转换的延迟表示形式。其具有模块化和灵活性的特点，这意味着可以将它们用作构建更复杂表达式的构建块。一个计算人体BMI的`polars` 示例表达式如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ffb38fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[(col(\"weight\")) / (col(\"height\").pow([dyn int: 2]))]"
      ],
      "text/plain": [
       "<Expr ['[(col(\"weight\")) / (col(\"heigh…'] at 0x10C8BF9A690>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.col(\"weight\") / (pl.col(\"height\") ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d2023",
   "metadata": {},
   "source": [
    "进一步的，为了方便，可以用变量存储表达式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24d4c264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(col(\"weight\")) / (col(\"height\").pow([dyn int: 2]))]\n"
     ]
    }
   ],
   "source": [
    "bmi_expr = pl.col(\"weight\") / (pl.col(\"height\") ** 2)\n",
    "print(bmi_expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c7d76f",
   "metadata": {},
   "source": [
    "## 执行环境(Context)\n",
    "因为表达式是延迟执行的，所以目前尚未进行任何计算。这就是我们需要使用执行环境的原因所在。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f7ffe",
   "metadata": {},
   "source": [
    "`polars` 表达式需要一个执行环境才能产生结果。根据其使用的语境不同，同一个“polars”表达式可能会产生不同的结果。结果。在本节中，我们将了解 `polars`所提供的四种最常见的应用场景，包括：`select, with_column, filter, group_by`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe43e60a",
   "metadata": {},
   "source": [
    "我们将使用下列`Datafreme`作为示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d104ee68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌────────────────┬────────────┬────────┬────────┐\n",
      "│ name           ┆ birthdate  ┆ weight ┆ height │\n",
      "│ ---            ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str            ┆ date       ┆ f64    ┆ f64    │\n",
      "╞════════════════╪════════════╪════════╪════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   │\n",
      "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   │\n",
      "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   │\n",
      "└────────────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice Archer\", \"Ben Brown\", \"Chloe Cooper\", \"Daniel Donovan\"],\n",
    "        \"birthdate\": [\n",
    "            date(1997, 1, 10),\n",
    "            date(1985, 2, 15),\n",
    "            date(1983, 3, 22),\n",
    "            date(1981, 4, 30),\n",
    "        ],\n",
    "        \"weight\": [57.9, 72.5, 53.6, 83.1],  # (kg)\n",
    "        \"height\": [1.56, 1.77, 1.65, 1.75],  # (m)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8a4c6",
   "metadata": {},
   "source": [
    "### select\n",
    "`select`基于表达式的列进行操作。这种选择操作可能生成新的列，这些列可以是聚合结果、其他列的组合或者是常量值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40d9092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "┌───────────┬───────────┬───────────────┐\n",
      "│ bmi       ┆ avg_bmi   ┆ ideal_max_bmi │\n",
      "│ ---       ┆ ---       ┆ ---           │\n",
      "│ f64       ┆ f64       ┆ i32           │\n",
      "╞═══════════╪═══════════╪═══════════════╡\n",
      "│ 23.791913 ┆ 23.438973 ┆ 25            │\n",
      "│ 23.141498 ┆ 23.438973 ┆ 25            │\n",
      "│ 19.687787 ┆ 23.438973 ┆ 25            │\n",
      "│ 27.134694 ┆ 23.438973 ┆ 25            │\n",
      "└───────────┴───────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(\n",
    "    bmi=bmi_expr,\n",
    "    avg_bmi=bmi_expr.mean(),\n",
    "    ideal_max_bmi=25,\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3460d9e",
   "metadata": {},
   "source": [
    "在`select`中的表达式必须生成长度完全相同的序列，否则必须生成一个标量值。\n",
    "\n",
    "标量值会进行扩展处理，以与剩余序列的长度相匹配。像上述所使用的数字这样的常量也会进行扩展处理。 同时，该操作也可以在表达式中进行。例如，考虑以下表达式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beb0474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 1)\n",
      "┌───────────┐\n",
      "│ deviation │\n",
      "│ ---       │\n",
      "│ f64       │\n",
      "╞═══════════╡\n",
      "│ 0.115645  │\n",
      "│ -0.097471 │\n",
      "│ -1.22912  │\n",
      "│ 1.210946  │\n",
      "└───────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.select(deviation=(bmi_expr - bmi_expr.mean()) / bmi_expr.std())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa609721",
   "metadata": {},
   "source": [
    "### with_columns\n",
    "`with_columns`与`select`非常相似。\n",
    "\n",
    "这两者的主要区别在于：`with_columns`会创建一个新的数据框，该数据框包含原始`DataFrame`中的列以及根据其输入表达式生成的新列；而`select`上下文仅包含由其输入表达式所选定的列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85604283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 7)\n",
      "┌────────────────┬────────────┬────────┬────────┬───────────┬───────────┬───────────────┐\n",
      "│ name           ┆ birthdate  ┆ weight ┆ height ┆ bmi       ┆ avg_bmi   ┆ ideal_max_bmi │\n",
      "│ ---            ┆ ---        ┆ ---    ┆ ---    ┆ ---       ┆ ---       ┆ ---           │\n",
      "│ str            ┆ date       ┆ f64    ┆ f64    ┆ f64       ┆ f64       ┆ i32           │\n",
      "╞════════════════╪════════════╪════════╪════════╪═══════════╪═══════════╪═══════════════╡\n",
      "│ Alice Archer   ┆ 1997-01-10 ┆ 57.9   ┆ 1.56   ┆ 23.791913 ┆ 23.438973 ┆ 25            │\n",
      "│ Ben Brown      ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   ┆ 23.141498 ┆ 23.438973 ┆ 25            │\n",
      "│ Chloe Cooper   ┆ 1983-03-22 ┆ 53.6   ┆ 1.65   ┆ 19.687787 ┆ 23.438973 ┆ 25            │\n",
      "│ Daniel Donovan ┆ 1981-04-30 ┆ 83.1   ┆ 1.75   ┆ 27.134694 ┆ 23.438973 ┆ 25            │\n",
      "└────────────────┴────────────┴────────┴────────┴───────────┴───────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.with_columns(\n",
    "    bmi=bmi_expr,\n",
    "    avg_bmi=bmi_expr.mean(),\n",
    "    ideal_max_bmi=25,\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc95b7",
   "metadata": {},
   "source": [
    "### filter\n",
    "\n",
    "`filter`会根据一个或多个表达式来筛选数据框中的行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b2fcde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 4)\n",
      "┌───────────┬────────────┬────────┬────────┐\n",
      "│ name      ┆ birthdate  ┆ weight ┆ height │\n",
      "│ ---       ┆ ---        ┆ ---    ┆ ---    │\n",
      "│ str       ┆ date       ┆ f64    ┆ f64    │\n",
      "╞═══════════╪════════════╪════════╪════════╡\n",
      "│ Ben Brown ┆ 1985-02-15 ┆ 72.5   ┆ 1.77   │\n",
      "└───────────┴────────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.filter(\n",
    "    pl.col(\"birthdate\").is_between(date(1982, 12, 31), date(1996, 1, 1)),\n",
    "    pl.col(\"height\") > 1.7,\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0603ac",
   "metadata": {},
   "source": [
    "### group_by和aggregations\n",
    "\n",
    "在`group_by`这一语境中，数据行会根据分组表达式的唯一值进行分组。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902e550",
   "metadata": {},
   "source": [
    "在使用了`group_by`之后，我们使用`agg`来对各个组应用聚合表达式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f09f4040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "┌────────┬─────────────────────────────────┐\n",
      "│ decade ┆ name                            │\n",
      "│ ---    ┆ ---                             │\n",
      "│ i32    ┆ list[str]                       │\n",
      "╞════════╪═════════════════════════════════╡\n",
      "│ 1980   ┆ [\"Ben Brown\", \"Chloe Cooper\", … │\n",
      "│ 1990   ┆ [\"Alice Archer\"]                │\n",
      "└────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.group_by(\n",
    "    (pl.col(\"birthdate\").dt.year() // 10 * 10).alias(\"decade\"),\n",
    ").agg(pl.col(\"name\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a2540e",
   "metadata": {},
   "source": [
    "由于在上述示例中我们仅指定了一个列的名称，所以我们会得到该列的各个组的列表形式。\n",
    "我们可以根据需要设定任意数量的分组表达式，而`group_by`会根据所指定表达式中的不同值对行进行分组。在此示例中，我们按照出生年代以及个人身高是否低于 1.7米这两个因素进行组合分组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8319060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 3)\n",
      "┌────────┬────────┬─────────────────────────────────┐\n",
      "│ decade ┆ short? ┆ name                            │\n",
      "│ ---    ┆ ---    ┆ ---                             │\n",
      "│ i32    ┆ bool   ┆ list[str]                       │\n",
      "╞════════╪════════╪═════════════════════════════════╡\n",
      "│ 1980   ┆ true   ┆ [\"Chloe Cooper\"]                │\n",
      "│ 1990   ┆ true   ┆ [\"Alice Archer\"]                │\n",
      "│ 1980   ┆ false  ┆ [\"Ben Brown\", \"Daniel Donovan\"… │\n",
      "└────────┴────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.group_by(\n",
    "    (pl.col(\"birthdate\").dt.year() // 10 * 10).alias(\"decade\"),\n",
    "    (pl.col(\"height\") < 1.7).alias(\"short?\"),\n",
    ").agg(pl.col(\"name\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b44fb",
   "metadata": {},
   "source": [
    "应用聚合表达式处理后生成的`DataFrame`中，每个聚合表达式都会对应一个列。\n",
    "\n",
    "首先在左侧列出每个分组表达式，然后根据需要列出相应的列来表示聚合表达式的结果。接着，我们可以指定任意数量的聚合表达式:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79e42952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 6)\n",
      "┌────────┬────────┬─────┬─────────┬────────────┬────────────┐\n",
      "│ decade ┆ short? ┆ len ┆ tallest ┆ avg_weight ┆ avg_height │\n",
      "│ ---    ┆ ---    ┆ --- ┆ ---     ┆ ---        ┆ ---        │\n",
      "│ i32    ┆ bool   ┆ u32 ┆ f64     ┆ f64        ┆ f64        │\n",
      "╞════════╪════════╪═════╪═════════╪════════════╪════════════╡\n",
      "│ 1990   ┆ true   ┆ 1   ┆ 1.56    ┆ 57.9       ┆ 1.56       │\n",
      "│ 1980   ┆ false  ┆ 2   ┆ 1.77    ┆ 77.8       ┆ 1.76       │\n",
      "│ 1980   ┆ true   ┆ 1   ┆ 1.65    ┆ 53.6       ┆ 1.65       │\n",
      "└────────┴────────┴─────┴─────────┴────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = df.group_by(\n",
    "    (pl.col(\"birthdate\").dt.year() // 10 * 10).alias(\"decade\"),\n",
    "    (pl.col(\"height\") < 1.7).alias(\"short?\"),\n",
    ").agg(\n",
    "    pl.len(),\n",
    "    pl.col(\"height\").max().alias(\"tallest\"),\n",
    "    pl.col(\"weight\", \"height\").mean().name.prefix(\"avg_\"),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4898f",
   "metadata": {},
   "source": [
    "由于表达式是惰性的，所以在将表达式置于某个上下文中使用时，polars会尝试在执行数据转换操作之前简化该表达式。在一个执行环境中，相互独立的表达式显然是可以并行处理的，`polars` 会充分利用这一点，同时在使用表达式扩展时也会对表达式执行进行并行化处理。\n",
    "\n",
    "而当使用 `polars` 的惰性 API时(接下来会介绍)，还能进一步获得性能提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301173a2",
   "metadata": {},
   "source": [
    "### 惰性API（Lazy API）\n",
    "\n",
    "`polars` 支持两种运行模式：惰性模式（Lazy API）和主动模式 (Eager API) 。\n",
    "\n",
    "到目前为止的示例均使用了主动API，在这种模式下，查询会立即执行。\n",
    "\n",
    "而在惰性模式中，只有在收集查询结果时才会对其进行评估。将执行操作推迟到最后一刻能够带来显著的性能优势，这也是为什么在大多数情况下，惰性 API更为被青睐。让我们通过一个示例来说明这一点:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "477fd7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "    \"age\": [25, 30, 35, 40, 45],\n",
    "    \"city\": [\"New York\", \"London\", \"Paris\", \"Tokyo\", \"Berlin\"],\n",
    "    \"salary\": [5000, 6000, 7000, 8000, 9000]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a497750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 2)\n",
      "┌────────┬────────┐\n",
      "│ city   ┆ salary │\n",
      "│ ---    ┆ ---    │\n",
      "│ str    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ Berlin ┆ 9000.0 │\n",
      "│ Paris  ┆ 7000.0 │\n",
      "│ Tokyo  ┆ 8000.0 │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# 使用主动API方式处理数据\n",
    "# df = pl.read_csv(\"output.csv\")\n",
    "df_filtered = df.filter(pl.col(\"age\") > 30)\n",
    "df_agg = df_filtered.group_by(\"city\").agg(pl.col(\"salary\").mean())\n",
    "\n",
    "print(df_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12618192",
   "metadata": {},
   "source": [
    "在本例中，我们使用主动API来：\n",
    "- 读取数据\n",
    "- 过滤年龄大于30的记录\n",
    "- 按城市分组并计算平均薪资 \n",
    "\n",
    "每一步操作都会立即执行，并返回中间结果。这可能会造成极大的浪费，因为我们可能会进行不必要的工作或加载未被使用的额外数据。如果我们改为使用延迟式 API，并等到所有步骤都定义好后再执行，那么查询规划器就能够进行各种优化。在这种情况下: \n",
    "- 谓词下推：在读取数据集时尽早应用过滤条件，这样就只读取年龄大于30的行。\n",
    "- 投影下推：在读取数据集时仅选择所需的列，从而无需加载额外的列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fe23111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 2)\n",
      "┌────────┬────────┐\n",
      "│ city   ┆ salary │\n",
      "│ ---    ┆ ---    │\n",
      "│ str    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ Tokyo  ┆ 8000.0 │\n",
      "│ Berlin ┆ 9000.0 │\n",
      "│ Paris  ┆ 7000.0 │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# 使用惰性API方式处理数据\n",
    "q = (\n",
    "    pl.scan_csv(\"assets/output.csv\")  \n",
    "    .filter(pl.col(\"age\") > 30)  \n",
    "    .group_by(\"city\")  \n",
    "    .agg(pl.col(\"salary\").mean())  \n",
    ")\n",
    "\n",
    "# 执行查询并获取结果\n",
    "df = q.collect()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49950031",
   "metadata": {},
   "source": [
    "这些操作将显著减轻内存和 CPU的负担，从而能够将更大的数据集存储在内存中并更快地进行处理。\n",
    "\n",
    "一旦定义好查询，我们就调用`collect`来通知`polars`想要执行该查询。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de25959",
   "metadata": {},
   "source": [
    "#### 何时使用惰性API\n",
    "\n",
    "一般来说，应优先使用惰性API，除非我们对中间结果感兴趣，或者正在进行探索性研究并且还不清楚最终查询结果是什么样子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96da9ac9",
   "metadata": {},
   "source": [
    "## 流式（Steaming）\n",
    "\n",
    "惰性 API的另一个优点是它允许以流式方式执行查询。与一次性处理所有数据不同。`polars`可以分批执行查询，使得当数据集无法全部装入内存时，也能处理。此外，与`polars` 的内存引擎相比，流式引擎的性能也更出色。\n",
    "\n",
    "要告知 `polars` 我们希望以流式模式执行查询，需要在代码中设置`engine='streaming'`这个参数。示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcd33f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (\n",
    "    pl.scan_csv(\"assets/output.csv\")  \n",
    "    .filter(pl.col(\"age\") > 30)  \n",
    "    .group_by(\"city\")  \n",
    "    .agg(pl.col(\"salary\").mean())  \n",
    ")\n",
    "\n",
    "# 执行流式查询并获取结果\n",
    "df = q.collect(engine=\"streaming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d474c3cd",
   "metadata": {},
   "source": [
    "## 读写数据\n",
    "\n",
    "`polars` 支持读取和写入常见的文件格式（例如 csv、json、parquet）、云存储（S3、Azure Blob、BigQuery）以及数据库（例如 postgres、mysql）。\n",
    "\n",
    "使用`read_csv` 函数读取 csv 文件,使用`write_csv` 函数写入 csv 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cd7e2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────┬─────┬──────────┬────────┐\n",
      "│ name    ┆ age ┆ city     ┆ salary │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---    │\n",
      "│ str     ┆ i64 ┆ str      ┆ i64    │\n",
      "╞═════════╪═════╪══════════╪════════╡\n",
      "│ Alice   ┆ 25  ┆ New York ┆ 5000   │\n",
      "│ Bob     ┆ 30  ┆ London   ┆ 6000   │\n",
      "│ Charlie ┆ 35  ┆ Paris    ┆ 7000   │\n",
      "│ David   ┆ 40  ┆ Tokyo    ┆ 8000   │\n",
      "│ Eve     ┆ 45  ┆ Berlin   ┆ 9000   │\n",
      "└─────────┴─────┴──────────┴────────┘\n",
      "shape: (3, 2)\n",
      "┌────────┬────────┐\n",
      "│ city   ┆ salary │\n",
      "│ ---    ┆ ---    │\n",
      "│ str    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ Tokyo  ┆ 8000.0 │\n",
      "│ Berlin ┆ 9000.0 │\n",
      "│ Paris  ┆ 7000.0 │\n",
      "└────────┴────────┘\n",
      "shape: (3, 2)\n",
      "┌────────┬────────┐\n",
      "│ city   ┆ salary │\n",
      "│ ---    ┆ ---    │\n",
      "│ str    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ Tokyo  ┆ 8000.0 │\n",
      "│ Berlin ┆ 9000.0 │\n",
      "│ Paris  ┆ 7000.0 │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 写入 CSV 文件\n",
    "# df.write_csv(\"output.csv\")\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df_from_csv = pl.read_csv(\"assets/output.csv\")\n",
    "print(df_from_csv)\n",
    "\n",
    "# 读写 Parquet 文件（更高效）\n",
    "# df.write_parquet(\"output.parquet\")\n",
    "df_from_parquet = pl.read_parquet(\"assets/output.parquet\")\n",
    "print(df_from_parquet)\n",
    "\n",
    "# 读写 JSON 文件\n",
    "# df.write_json(\"output.json\")\n",
    "df_from_json = pl.read_json(\"assets/output.json\")\n",
    "print(df_from_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f4700",
   "metadata": {},
   "source": [
    "## 与 pandas 对比\n",
    "性能对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90ad0a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polars 处理时间: 0.022 秒\n",
      "pandas 处理时间: 0.058 秒\n",
      "速度提升: 2.7 倍\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 创建大型数据集\n",
    "n_rows = 1_000_000\n",
    "data = {\n",
    "    \"x\": np.random.randn(n_rows),\n",
    "    \"y\": np.random.randn(n_rows),\n",
    "    \"category\": np.random.choice([\"A\", \"B\", \"C\"], n_rows)\n",
    "}\n",
    "\n",
    "# 创建 polars DataFrame\n",
    "df_polars = pl.DataFrame(data)\n",
    "\n",
    "# 创建 pandas DataFrame\n",
    "df_pandas = pd.DataFrame(data)\n",
    "\n",
    "# 测量聚合操作的时间\n",
    "start_time = time.time()\n",
    "result_polars = df_polars.group_by(\"category\").agg(pl.col(\"x\").mean())\n",
    "end_time = time.time()\n",
    "polars_time = end_time - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "result_pandas = df_pandas.groupby(\"category\")[\"x\"].mean()\n",
    "end_time = time.time()\n",
    "pandas_time = end_time - start_time\n",
    "\n",
    "print(f\"polars 处理时间: {polars_time:.3f} 秒\")\n",
    "print(f\"pandas 处理时间: {pandas_time:.3f} 秒\")\n",
    "print(f\"速度提升: {pandas_time/polars_time:.1f} 倍\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e63882",
   "metadata": {},
   "source": [
    "内存使用对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e642ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polars 内存使用: 0.00 MB\n",
      "pandas 内存使用: 70.57 MB\n",
      "内存节省: 1321431.5 倍\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# 查看内存使用\n",
    "polars_memory = sys.getsizeof(df_polars)\n",
    "pandas_memory = sys.getsizeof(df_pandas)\n",
    "\n",
    "print(f\"polars 内存使用: {polars_memory / 1024 / 1024:.2f} MB\")\n",
    "print(f\"pandas 内存使用: {pandas_memory / 1024 / 1024:.2f} MB\")\n",
    "print(f\"内存节省: {pandas_memory/polars_memory:.1f} 倍\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef2a9b",
   "metadata": {},
   "source": [
    "### 与 pandas 互操作\n",
    "`polars`可以轻松与 `pandas`进行互操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fb61ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     city  salary\n",
      "0   Tokyo  8000.0\n",
      "1  Berlin  9000.0\n",
      "2   Paris  7000.0\n",
      "<class 'polars.dataframe.frame.DataFrame'>\n",
      "shape: (3, 2)\n",
      "┌────────┬────────┐\n",
      "│ city   ┆ salary │\n",
      "│ ---    ┆ ---    │\n",
      "│ str    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ Tokyo  ┆ 8000.0 │\n",
      "│ Berlin ┆ 9000.0 │\n",
      "│ Paris  ┆ 7000.0 │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# 转换为 pandas DataFrame\n",
    "pandas_df = df.to_pandas()\n",
    "print(type(pandas_df))\n",
    "print(pandas_df.head())\n",
    "\n",
    "# 从 pandas DataFrame 创建\n",
    "df_from_pandas = pl.from_pandas(pandas_df)\n",
    "print(type(df_from_pandas))\n",
    "print(df_from_pandas.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf70d2f",
   "metadata": {},
   "source": [
    "### 高级功能\n",
    "\n",
    "表达式 API\n",
    "\n",
    "`polars`的表达式 API 提供了强大的数据操作能力："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3d01020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "    \"age\": [25, 30, 35, 40, 45],\n",
    "    \"city\": [\"New York\", \"London\", \"Paris\", \"Tokyo\", \"Berlin\"],\n",
    "    \"salary\": [5000, 6000, 7000, 8000, 9000]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8219c33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌─────────┬─────┬────────┬────────────────┬─────────────────┐\n",
      "│ name    ┆ age ┆ salary ┆ salary_per_age ┆ adjusted_salary │\n",
      "│ ---     ┆ --- ┆ ---    ┆ ---            ┆ ---             │\n",
      "│ str     ┆ i64 ┆ i64    ┆ f64            ┆ f64             │\n",
      "╞═════════╪═════╪════════╪════════════════╪═════════════════╡\n",
      "│ Alice   ┆ 25  ┆ 5000   ┆ 200.0          ┆ 5000.0          │\n",
      "│ Bob     ┆ 30  ┆ 6000   ┆ 200.0          ┆ 6000.0          │\n",
      "│ Charlie ┆ 35  ┆ 7000   ┆ 200.0          ┆ 7700.0          │\n",
      "│ David   ┆ 40  ┆ 8000   ┆ 200.0          ┆ 8800.0          │\n",
      "│ Eve     ┆ 45  ┆ 9000   ┆ 200.0          ┆ 9900.0          │\n",
      "└─────────┴─────┴────────┴────────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# 使用表达式进行复杂操作\n",
    "result = df.select([\n",
    "    pl.col(\"name\"),\n",
    "    pl.col(\"age\"),\n",
    "    pl.col(\"salary\"),\n",
    "    (pl.col(\"salary\") / pl.col(\"age\")).alias(\"salary_per_age\"),\n",
    "    pl.when(pl.col(\"age\") > 30)\n",
    "      .then(pl.col(\"salary\") * 1.1)\n",
    "      .otherwise(pl.col(\"salary\"))\n",
    "      .alias(\"adjusted_salary\")\n",
    "])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005bd82",
   "metadata": {},
   "source": [
    "时间序列处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33379ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 2)\n",
      "┌────────────┬───────┐\n",
      "│ date       ┆ value │\n",
      "│ ---        ┆ ---   │\n",
      "│ date       ┆ i64   │\n",
      "╞════════════╪═══════╡\n",
      "│ 2023-01-01 ┆ 1     │\n",
      "│ 2023-01-02 ┆ 2     │\n",
      "│ 2023-01-03 ┆ 3     │\n",
      "│ 2023-01-04 ┆ 4     │\n",
      "│ 2023-01-05 ┆ 5     │\n",
      "│ 2023-01-06 ┆ 6     │\n",
      "│ 2023-01-07 ┆ 7     │\n",
      "│ 2023-01-08 ┆ 8     │\n",
      "│ 2023-01-09 ┆ 9     │\n",
      "│ 2023-01-10 ┆ 10    │\n",
      "└────────────┴───────┘\n",
      "shape: (10, 5)\n",
      "┌────────────┬───────┬──────┬──────┬──────────────┐\n",
      "│ date       ┆ value ┆ diff ┆ lag  ┆ rolling_mean │\n",
      "│ ---        ┆ ---   ┆ ---  ┆ ---  ┆ ---          │\n",
      "│ date       ┆ i64   ┆ i64  ┆ i64  ┆ f64          │\n",
      "╞════════════╪═══════╪══════╪══════╪══════════════╡\n",
      "│ 2023-01-01 ┆ 1     ┆ null ┆ null ┆ null         │\n",
      "│ 2023-01-02 ┆ 2     ┆ 1    ┆ 1    ┆ null         │\n",
      "│ 2023-01-03 ┆ 3     ┆ 1    ┆ 2    ┆ 2.0          │\n",
      "│ 2023-01-04 ┆ 4     ┆ 1    ┆ 3    ┆ 3.0          │\n",
      "│ 2023-01-05 ┆ 5     ┆ 1    ┆ 4    ┆ 4.0          │\n",
      "│ 2023-01-06 ┆ 6     ┆ 1    ┆ 5    ┆ 5.0          │\n",
      "│ 2023-01-07 ┆ 7     ┆ 1    ┆ 6    ┆ 6.0          │\n",
      "│ 2023-01-08 ┆ 8     ┆ 1    ┆ 7    ┆ 7.0          │\n",
      "│ 2023-01-09 ┆ 9     ┆ 1    ┆ 8    ┆ 8.0          │\n",
      "│ 2023-01-10 ┆ 10    ┆ 1    ┆ 9    ┆ 9.0          │\n",
      "└────────────┴───────┴──────┴──────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# 创建时间序列数据\n",
    "date_ranges = pl.date_range(\n",
    "    start=pl.datetime(2023, 1, 1),\n",
    "    end=pl.datetime(2023, 1, 10),\n",
    "    interval=\"1d\",\n",
    "    eager=True\n",
    ")\n",
    "\n",
    "ts_df = pl.DataFrame({\n",
    "    \"date\": date_ranges,\n",
    "    \"value\": range(1, 11)\n",
    "})\n",
    "print(ts_df)\n",
    "\n",
    "# 时间序列操作\n",
    "ts_result = ts_df.with_columns([\n",
    "    pl.col(\"value\").diff().alias(\"diff\"),\n",
    "    pl.col(\"value\").shift(1).alias(\"lag\"),\n",
    "    pl.col(\"value\").rolling_mean(window_size=3).alias(\"rolling_mean\")\n",
    "])\n",
    "print(ts_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9248451",
   "metadata": {},
   "source": [
    "## 总结\n",
    "`polars`是一个强大且高效的数据处理库，具有以下优势：\n",
    "\n",
    "- 出色的性能，尤其适合处理大型数据集\n",
    "\n",
    "- 内存效率高，支持惰性执行\n",
    "\n",
    "- 丰富的数据操作功能\n",
    "\n",
    "- 良好的生态系统集成\n",
    "\n",
    "对于需要处理大规模数据的应用场景，`polars`是一个很好的选择。对于熟悉 `pandas`的用户，`polars`的学习曲线相对平缓，大部分概念和操作都是相通的。\n",
    "\n",
    "#### 何时选择 polars 而不是 pandas：\n",
    "\n",
    "- 处理大型数据集（GB 级别或更大）\n",
    "\n",
    "- 需要最佳性能\n",
    "\n",
    "- 内存受限的环境\n",
    "\n",
    "- 需要多线程处理\n",
    "\n",
    "#### 何时选择 pandas 而不是 polars：\n",
    "\n",
    "- 需要与丰富的 `pandas` 生态系统集成\n",
    "\n",
    "- 使用许多专门的数据分析库\n",
    "\n",
    "- 处理小型数据集且开发速度更重要\n",
    "\n",
    "更多详细信息和高级用法，请参考 [polars 官方文档](https://pola.rs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
